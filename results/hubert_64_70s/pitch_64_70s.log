train at step 1510: 0.5562499761581421
train loss at step 1510: 1.1659786701202393
train at step 1520: 0.800000011920929
train loss at step 1520: 0.3835218548774719
train at step 1530: 0.918749988079071
train loss at step 1530: 0.1990758627653122
dev at step 1530: 0.5
New best on dev at step 1530: 0.5
dev loss at step 1530: 4.660122394561768
test at step 1530: 0.7770270109176636
test loss at step 1530: 1.4685826301574707
tp: 112, tn: 3, fp: 28, fn: 5
accuracy: 0.777027027027027, precision: 0.8, recall: 0.9572649572649573, F1: 0.8715953307392997
specificity: 0.0967741935483871, gmean: 0.30436580663972007, mcc: 0.09724634385073437 

train at step 1540: 0.956250011920929
train loss at step 1540: 0.10128766298294067
train at step 1550: 0.96875
train loss at step 1550: 0.07506342977285385
train at step 1560: 0.9437500238418579
train loss at step 1560: 0.11796233803033829
dev at step 1560: 0.5
dev loss at step 1560: 4.677603721618652
test at step 1560: 0.75
test loss at step 1560: 1.5271170139312744
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1570: 1.0
train loss at step 1570: 0.02693631872534752
train at step 1580: 1.0
train loss at step 1580: 0.014857500791549683
train at step 1590: 1.0
train loss at step 1590: 0.02028047665953636
dev at step 1590: 0.5
dev loss at step 1590: 5.559345245361328
test at step 1590: 0.75
test loss at step 1590: 1.7785805463790894
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1600: 0.9937499761581421
train loss at step 1600: 0.016893895342946053
train at step 1610: 1.0
train loss at step 1610: 0.007401380687952042
train at step 1620: 1.0
train loss at step 1620: 0.01348885428160429
dev at step 1620: 0.5
dev loss at step 1620: 4.244912147521973
test at step 1620: 0.7364864945411682
test loss at step 1620: 1.603512167930603
tp: 102, tn: 7, fp: 24, fn: 15
accuracy: 0.7364864864864865, precision: 0.8095238095238095, recall: 0.8717948717948718, F1: 0.8395061728395062
specificity: 0.22580645161290322, gmean: 0.4436855942379985, mcc: 0.11164335300719826 

train at step 1630: 1.0
train loss at step 1630: 0.013672016561031342
train at step 1640: 0.9937499761581421
train loss at step 1640: 0.017755616456270218
train at step 1650: 0.987500011920929
train loss at step 1650: 0.027724098414182663
dev at step 1650: 0.5
dev loss at step 1650: 4.761810302734375
test at step 1650: 0.7364864945411682
test loss at step 1650: 1.7225948572158813
tp: 103, tn: 6, fp: 25, fn: 14
accuracy: 0.7364864864864865, precision: 0.8046875, recall: 0.8803418803418803, F1: 0.8408163265306122
specificity: 0.1935483870967742, gmean: 0.4127817232314342, mcc: 0.08795105100272621 

train at step 1660: 1.0
train loss at step 1660: 0.00672957394272089
train at step 1670: 1.0
train loss at step 1670: 0.0023150057531893253
train at step 1680: 1.0
train loss at step 1680: 0.004241409711539745
dev at step 1680: 0.5
dev loss at step 1680: 5.403963565826416
test at step 1680: 0.7364864945411682
test loss at step 1680: 1.8476588726043701
tp: 104, tn: 5, fp: 26, fn: 13
accuracy: 0.7364864864864865, precision: 0.8, recall: 0.8888888888888888, F1: 0.8421052631578948
specificity: 0.16129032258064516, gmean: 0.3786412228313765, mcc: 0.06247261447019436 

train at step 1690: 1.0
train loss at step 1690: 0.003297865856438875
train at step 1700: 1.0
train loss at step 1700: 0.003418500768020749
train at step 1710: 1.0
train loss at step 1710: 0.006191858556121588
dev at step 1710: 0.5
dev loss at step 1710: 5.9460978507995605
test at step 1710: 0.7432432174682617
test loss at step 1710: 1.9652119874954224
tp: 105, tn: 5, fp: 26, fn: 12
accuracy: 0.7432432432432432, precision: 0.8015267175572519, recall: 0.8974358974358975, F1: 0.8467741935483871
specificity: 0.16129032258064516, gmean: 0.3804572582996501, mcc: 0.07494552688310403 

train at step 1720: 1.0
train loss at step 1720: 0.002221000147983432
train at step 1730: 1.0
train loss at step 1730: 0.002060599159449339
train at step 1740: 1.0
train loss at step 1740: 0.001827086671255529
dev at step 1740: 0.5
dev loss at step 1740: 6.108363628387451
test at step 1740: 0.7432432174682617
test loss at step 1740: 2.016873359680176
tp: 105, tn: 5, fp: 26, fn: 12
accuracy: 0.7432432432432432, precision: 0.8015267175572519, recall: 0.8974358974358975, F1: 0.8467741935483871
specificity: 0.16129032258064516, gmean: 0.3804572582996501, mcc: 0.07494552688310403 

train at step 1750: 1.0
train loss at step 1750: 0.001433451776392758
train at step 1760: 1.0
train loss at step 1760: 0.0009457052801735699
train at step 1770: 1.0
train loss at step 1770: 0.0011685587232932448
dev at step 1770: 0.5
dev loss at step 1770: 6.563689708709717
test at step 1770: 0.7432432174682617
test loss at step 1770: 2.120760440826416
tp: 106, tn: 4, fp: 27, fn: 11
accuracy: 0.7432432432432432, precision: 0.7969924812030075, recall: 0.905982905982906, F1: 0.848
specificity: 0.12903225806451613, gmean: 0.34190791176401075, mcc: 0.047212662557578174 

train at step 1780: 1.0
train loss at step 1780: 0.000748993072193116
train at step 1790: 1.0
train loss at step 1790: 0.000751989777199924
train at step 1800: 1.0
train loss at step 1800: 0.0008995693060569465
dev at step 1800: 0.5
dev loss at step 1800: 6.623745441436768
test at step 1800: 0.7432432174682617
test loss at step 1800: 2.1409544944763184
tp: 106, tn: 4, fp: 27, fn: 11
accuracy: 0.7432432432432432, precision: 0.7969924812030075, recall: 0.905982905982906, F1: 0.848
specificity: 0.12903225806451613, gmean: 0.34190791176401075, mcc: 0.047212662557578174 

train at step 1810: 1.0
train loss at step 1810: 0.0008544532465748489
train at step 1820: 1.0
train loss at step 1820: 0.0006221586954779923
train at step 1830: 1.0
train loss at step 1830: 0.0008030331810005009
dev at step 1830: 0.5
dev loss at step 1830: 6.851519584655762
test at step 1830: 0.75
test loss at step 1830: 2.196650505065918
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1840: 1.0
train loss at step 1840: 0.000607277499511838
train at step 1850: 1.0
train loss at step 1850: 0.0006009023636579514
train at step 1860: 1.0
train loss at step 1860: 0.0007192507619038224
dev at step 1860: 0.5
dev loss at step 1860: 6.816850662231445
test at step 1860: 0.7432432174682617
test loss at step 1860: 2.194671630859375
tp: 106, tn: 4, fp: 27, fn: 11
accuracy: 0.7432432432432432, precision: 0.7969924812030075, recall: 0.905982905982906, F1: 0.848
specificity: 0.12903225806451613, gmean: 0.34190791176401075, mcc: 0.047212662557578174 

train at step 1870: 1.0
train loss at step 1870: 0.0006912552053108811
train at step 1880: 1.0
train loss at step 1880: 0.0005116185056976974
train at step 1890: 1.0
train loss at step 1890: 0.0006583615322597325
dev at step 1890: 0.5
dev loss at step 1890: 6.985217094421387
test at step 1890: 0.75
test loss at step 1890: 2.2368874549865723
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1900: 1.0
train loss at step 1900: 0.0004996747011318803
train at step 1910: 1.0
train loss at step 1910: 0.0005001283134333789
train at step 1920: 1.0
train loss at step 1920: 0.0005901503027416766
dev at step 1920: 0.5
dev loss at step 1920: 6.9906816482543945
test at step 1920: 0.75
test loss at step 1920: 2.24291729927063
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1930: 1.0
train loss at step 1930: 0.0005763000808656216
train at step 1940: 1.0
train loss at step 1940: 0.0004321405722294003
train at step 1950: 1.0
train loss at step 1950: 0.0005541426944546402
dev at step 1950: 0.5
dev loss at step 1950: 7.109372138977051
test at step 1950: 0.75
test loss at step 1950: 2.2737905979156494
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1960: 1.0
train loss at step 1960: 0.00042173569090664387
train at step 1970: 1.0
train loss at step 1970: 0.0004252912476658821
train at step 1980: 1.0
train loss at step 1980: 0.0004994679475203156
dev at step 1980: 0.5
dev loss at step 1980: 7.130237102508545
test at step 1980: 0.75
test loss at step 1980: 2.282689094543457
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 1990: 1.0
train loss at step 1990: 0.000492784078232944
train at step 2000: 1.0
train loss at step 2000: 0.0003721719840541482
train at step 2010: 1.0
train loss at step 2010: 0.0004752335953526199
dev at step 2010: 0.5
dev loss at step 2010: 7.228701591491699
test at step 2010: 0.75
test loss at step 2010: 2.30873966217041
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 2020: 1.0
train loss at step 2020: 0.0003637616173364222
train at step 2030: 1.0
train loss at step 2030: 0.00036782390088774264
train at step 2040: 1.0
train loss at step 2040: 0.000431944674346596
dev at step 2040: 0.5
dev loss at step 2040: 7.254242420196533
test at step 2040: 0.75
test loss at step 2040: 2.318277359008789
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 2050: 1.0
train loss at step 2050: 0.0004284956958144903
train at step 2060: 1.0
train loss at step 2060: 0.0003253586182836443
train at step 2070: 1.0
train loss at step 2070: 0.0004137785581406206
dev at step 2070: 0.5
dev loss at step 2070: 7.341500759124756
test at step 2070: 0.75
test loss at step 2070: 2.341567277908325
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 2080: 1.0
train loss at step 2080: 0.0003186986141372472
train at step 2090: 1.0
train loss at step 2090: 0.0003222858067601919
train at step 2100: 1.0
train loss at step 2100: 0.00037920151953585446
dev at step 2100: 0.5
dev loss at step 2100: 7.369759559631348
test at step 2100: 0.75
test loss at step 2100: 2.351402997970581
tp: 107, tn: 4, fp: 27, fn: 10
accuracy: 0.75, precision: 0.7985074626865671, recall: 0.9145299145299145, F1: 0.852589641434263
specificity: 0.12903225806451613, gmean: 0.3435168990593386, mcc: 0.060571299639702855 

train at step 2110: 1.0
train loss at step 2110: 0.00037729012547060847
train at step 2120: 1.0
train loss at step 2120: 0.0002876980579458177
train at step 2130: 1.0
train loss at step 2130: 0.0003644999233074486
dev at step 2130: 0.5
dev loss at step 2130: 7.449782848358154
test at step 2130: 0.7567567825317383
test loss at step 2130: 2.3728690147399902
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2140: 1.0
train loss at step 2140: 0.0002826154523063451
train at step 2150: 1.0
train loss at step 2150: 0.0002853281330317259
train at step 2160: 1.0
train loss at step 2160: 0.0003366667660884559
dev at step 2160: 0.5
dev loss at step 2160: 7.4799699783325195
test at step 2160: 0.7567567825317383
test loss at step 2160: 2.382892608642578
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2170: 1.0
train loss at step 2170: 0.00033547834027558565
train at step 2180: 1.0
train loss at step 2180: 0.00025667838053777814
train at step 2190: 1.0
train loss at step 2190: 0.0003240931255277246
dev at step 2190: 0.5
dev loss at step 2190: 7.554777145385742
test at step 2190: 0.7567567825317383
test loss at step 2190: 2.4030258655548096
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2200: 1.0
train loss at step 2200: 0.0002530464553274214
train at step 2210: 1.0
train loss at step 2210: 0.0002548085176385939
train at step 2220: 1.0
train loss at step 2220: 0.00030150741804391146
dev at step 2220: 0.5
dev loss at step 2220: 7.586172103881836
test at step 2220: 0.7567567825317383
test loss at step 2220: 2.413123369216919
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2230: 1.0
train loss at step 2230: 0.0003006765036843717
train at step 2240: 1.0
train loss at step 2240: 0.00023068347945809364
train at step 2250: 1.0
train loss at step 2250: 0.0002904032007791102
dev at step 2250: 0.5
dev loss at step 2250: 7.656680107116699
test at step 2250: 0.7567567825317383
test loss at step 2250: 2.4321582317352295
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2260: 1.0
train loss at step 2260: 0.00022827289649285376
train at step 2270: 1.0
train loss at step 2270: 0.0002292704302817583
train at step 2280: 1.0
train loss at step 2280: 0.0002718722098506987
dev at step 2280: 0.5
dev loss at step 2280: 7.68842887878418
test at step 2280: 0.7567567825317383
test loss at step 2280: 2.442171335220337
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2290: 1.0
train loss at step 2290: 0.0002712779678404331
train at step 2300: 1.0
train loss at step 2300: 0.00020862433302681893
train at step 2310: 1.0
train loss at step 2310: 0.00026193735538981855
dev at step 2310: 0.5
dev loss at step 2310: 7.755047798156738
test at step 2310: 0.7567567825317383
test loss at step 2310: 2.460217237472534
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2320: 1.0
train loss at step 2320: 0.00020717042207252234
train at step 2330: 1.0
train loss at step 2330: 0.00020766330999322236
train at step 2340: 1.0
train loss at step 2340: 0.00024652190040796995
dev at step 2340: 0.5
dev loss at step 2340: 7.786318778991699
test at step 2340: 0.7567567825317383
test loss at step 2340: 2.469980478286743
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2350: 1.0
train loss at step 2350: 0.00024615778238512576
train at step 2360: 1.0
train loss at step 2360: 0.00018970745441038162
train at step 2370: 1.0
train loss at step 2370: 0.00023763556964695454
dev at step 2370: 0.5
dev loss at step 2370: 7.8492889404296875
test at step 2370: 0.7567567825317383
test loss at step 2370: 2.4871034622192383
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2380: 1.0
train loss at step 2380: 0.00018895600805990398
train at step 2390: 1.0
train loss at step 2390: 0.00018917047418653965
train at step 2400: 1.0
train loss at step 2400: 0.00022461458866018802
dev at step 2400: 0.5
dev loss at step 2400: 7.879535675048828
test at step 2400: 0.7567567825317383
test loss at step 2400: 2.4965097904205322
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2410: 1.0
train loss at step 2410: 0.00022448626987170428
train at step 2420: 1.0
train loss at step 2420: 0.00017334397125523537
train at step 2430: 1.0
train loss at step 2430: 0.00021668404224328697
dev at step 2430: 0.5
dev loss at step 2430: 7.939077377319336
test at step 2430: 0.7567567825317383
test loss at step 2430: 2.5127663612365723
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2440: 1.0
train loss at step 2440: 0.00017309703980572522
train at step 2450: 1.0
train loss at step 2450: 0.0001731821830617264
train at step 2460: 1.0
train loss at step 2460: 0.00020552489149849862
dev at step 2460: 0.5
dev loss at step 2460: 7.968041896820068
test at step 2460: 0.7567567825317383
test loss at step 2460: 2.5217695236206055
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2470: 1.0
train loss at step 2470: 0.0002056537923635915
train at step 2480: 1.0
train loss at step 2480: 0.0001590821921126917
train at step 2490: 1.0
train loss at step 2490: 0.0001984869595617056
dev at step 2490: 0.5
dev loss at step 2490: 8.024515151977539
test at step 2490: 0.7567567825317383
test loss at step 2490: 2.537248134613037
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2500: 1.0
train loss at step 2500: 0.00015918235294520855
train at step 2510: 1.0
train loss at step 2510: 0.00015921742306090891
train at step 2520: 1.0
train loss at step 2520: 0.00018879419076256454
dev at step 2520: 0.5
dev loss at step 2520: 8.052167892456055
test at step 2520: 0.7567567825317383
test loss at step 2520: 2.5458526611328125
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2530: 1.0
train loss at step 2530: 0.0001891564461402595
train at step 2540: 1.0
train loss at step 2540: 0.00014654139522463083
train at step 2550: 1.0
train loss at step 2550: 0.00018255060422234237
dev at step 2550: 0.5
dev loss at step 2550: 8.105908393859863
test at step 2550: 0.7567567825317383
test loss at step 2550: 2.560636043548584
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2560: 1.0
train loss at step 2560: 0.00014688904047943652
train at step 2570: 1.0
train loss at step 2570: 0.00014692361583001912
train at step 2580: 1.0
train loss at step 2580: 0.0001740350271575153
dev at step 2580: 0.5
dev loss at step 2580: 8.13232421875
test at step 2580: 0.7567567825317383
test loss at step 2580: 2.568868637084961
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2590: 1.0
train loss at step 2590: 0.000174602959305048
train at step 2600: 1.0
train loss at step 2600: 0.00013544327521231025
train at step 2610: 1.0
train loss at step 2610: 0.00016849557869136333
dev at step 2610: 0.5
dev loss at step 2610: 8.183662414550781
test at step 2610: 0.7567567825317383
test loss at step 2610: 2.5830366611480713
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2620: 1.0
train loss at step 2620: 0.00013597049110103399
train at step 2630: 1.0
train loss at step 2630: 0.00013601858518086374
train at step 2640: 1.0
train loss at step 2640: 0.00016095190949272364
dev at step 2640: 0.5
dev loss at step 2640: 8.208946228027344
test at step 2640: 0.7567567825317383
test loss at step 2640: 2.5909295082092285
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2650: 1.0
train loss at step 2650: 0.00016168814909178764
train at step 2660: 1.0
train loss at step 2660: 0.00012557036825455725
train at step 2670: 1.0
train loss at step 2670: 0.00015603301289957017
dev at step 2670: 0.5
dev loss at step 2670: 8.258195877075195
test at step 2670: 0.7567567825317383
test loss at step 2670: 2.604560613632202
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2680: 1.0
train loss at step 2680: 0.00012621350469999015
train at step 2690: 1.0
train loss at step 2690: 0.00012627951218746603
train at step 2700: 1.0
train loss at step 2700: 0.00014928945165593177
dev at step 2700: 0.5
dev loss at step 2700: 8.282500267028809
test at step 2700: 0.7567567825317383
test loss at step 2700: 2.6121573448181152
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2710: 1.0
train loss at step 2710: 0.00015015123062767088
train at step 2720: 1.0
train loss at step 2720: 0.00011672355321934447
train at step 2730: 1.0
train loss at step 2730: 0.0001449013943783939
dev at step 2730: 0.5
dev loss at step 2730: 8.329935073852539
test at step 2730: 0.7567567825317383
test loss at step 2730: 2.6253185272216797
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2740: 1.0
train loss at step 2740: 0.00011745387746486813
train at step 2750: 1.0
train loss at step 2750: 0.00011753996659535915
train at step 2760: 1.0
train loss at step 2760: 0.00013883518113289028
dev at step 2760: 0.5
dev loss at step 2760: 8.353352546691895
test at step 2760: 0.7567567825317383
test loss at step 2760: 2.632646083831787
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2770: 1.0
train loss at step 2770: 0.0001398020249325782
train at step 2780: 1.0
train loss at step 2780: 0.00010876992018893361
train at step 2790: 1.0
train loss at step 2790: 0.00013490530545823276
dev at step 2790: 0.5
dev loss at step 2790: 8.399158477783203
test at step 2790: 0.7567567825317383
test loss at step 2790: 2.6453840732574463
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2800: 1.0
train loss at step 2800: 0.00010956304322462529
train at step 2810: 1.0
train loss at step 2810: 0.00010966024274239317
train at step 2820: 1.0
train loss at step 2820: 0.00012942569446749985
dev at step 2820: 0.5
dev loss at step 2820: 8.42180061340332
test at step 2820: 0.7567567825317383
test loss at step 2820: 2.6524758338928223
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2830: 1.0
train loss at step 2830: 0.00013046959065832198
train at step 2840: 1.0
train loss at step 2840: 0.00010158387885894626
train at step 2850: 1.0
train loss at step 2850: 0.0001259006530744955
dev at step 2850: 0.5
dev loss at step 2850: 8.466142654418945
test at step 2850: 0.7567567825317383
test loss at step 2850: 2.6648316383361816
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2860: 1.0
train loss at step 2860: 0.00010241239942843094
train at step 2870: 1.0
train loss at step 2870: 0.00010252888023387641
train at step 2880: 1.0
train loss at step 2880: 0.00012091609823983163
dev at step 2880: 0.5
dev loss at step 2880: 8.488058090209961
test at step 2880: 0.7567567825317383
test loss at step 2880: 2.6717021465301514
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2890: 1.0
train loss at step 2890: 0.00012201268691569567
train at step 2900: 1.0
train loss at step 2900: 9.506063361186534e-05
train at step 2910: 1.0
train loss at step 2910: 0.00011774023005273193
dev at step 2910: 0.5
dev loss at step 2910: 8.531133651733398
test at step 2910: 0.7567567825317383
test loss at step 2910: 2.6837270259857178
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2920: 1.0
train loss at step 2920: 9.592015703674406e-05
train at step 2930: 1.0
train loss at step 2930: 9.604253864381462e-05
train at step 2940: 1.0
train loss at step 2940: 0.00011319343320792541
dev at step 2940: 0.5
dev loss at step 2940: 8.552389144897461
test at step 2940: 0.7567567825317383
test loss at step 2940: 2.690396308898926
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2950: 1.0
train loss at step 2950: 0.00011431833263486624
train at step 2960: 1.0
train loss at step 2960: 8.912512566894293e-05
train at step 2970: 1.0
train loss at step 2970: 0.00011032445036107674
dev at step 2970: 0.5
dev loss at step 2970: 8.594318389892578
test at step 2970: 0.7567567825317383
test loss at step 2970: 2.702120304107666
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

train at step 2980: 1.0
train loss at step 2980: 8.999116107588634e-05
train at step 2990: 1.0
train loss at step 2990: 9.013132512336597e-05
train at step 3000: 1.0
train loss at step 3000: 0.0001061596121871844
dev at step 3000: 0.5
dev loss at step 3000: 8.614970207214355
test at step 3000: 0.7567567825317383
test loss at step 3000: 2.708603620529175
tp: 108, tn: 4, fp: 27, fn: 9
accuracy: 0.7567567567567568, precision: 0.8, recall: 0.9230769230769231, F1: 0.8571428571428571
specificity: 0.12903225806451613, gmean: 0.3451183851258305, mcc: 0.07491166777664257 

