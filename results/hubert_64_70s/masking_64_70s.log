train at step 10: 0.4625000059604645
train loss at step 10: 0.9039843678474426
train at step 20: 0.49056604504585266
train loss at step 20: 0.800338625907898
train at step 30: 0.553459107875824
train loss at step 30: 0.7206959128379822
train at step 40: 0.65625
train loss at step 40: 0.6114844083786011
train at step 50: 0.6100628972053528
train loss at step 50: 0.707817792892456
train at step 60: 0.6226415038108826
train loss at step 60: 0.6277948617935181
train at step 70: 0.731249988079071
train loss at step 70: 0.5517181158065796
train at step 80: 0.7421383857727051
train loss at step 80: 0.5126455426216125
train at step 90: 0.7610062956809998
train loss at step 90: 0.47804394364356995
train at step 100: 0.75
train loss at step 100: 0.5185219049453735
train at step 110: 0.7106918096542358
train loss at step 110: 0.5561984777450562
train at step 120: 0.7232704162597656
train loss at step 120: 0.5133535861968994
train at step 130: 0.7562500238418579
train loss at step 130: 0.4943017363548279
train at step 140: 0.8113207817077637
train loss at step 140: 0.4200272560119629
train at step 150: 0.805031418800354
train loss at step 150: 0.4333930015563965
train at step 160: 0.824999988079071
train loss at step 160: 0.39302533864974976
train at step 170: 0.7295597195625305
train loss at step 170: 0.5264972448348999
train at step 180: 0.7924528121948242
train loss at step 180: 0.4082251489162445
train at step 190: 0.800000011920929
train loss at step 190: 0.4024721086025238
train at step 200: 0.7295597195625305
train loss at step 200: 0.4772648811340332
train at step 210: 0.8176100850105286
train loss at step 210: 0.4191746115684509
train at step 220: 0.8187500238418579
train loss at step 220: 0.3646230697631836
train at step 230: 0.8176100850105286
train loss at step 230: 0.37508103251457214
train at step 240: 0.805031418800354
train loss at step 240: 0.39020296931266785
train at step 250: 0.8187500238418579
train loss at step 250: 0.3775799870491028
train at step 260: 0.7924528121948242
train loss at step 260: 0.4519261419773102
train at step 270: 0.8301886916160583
train loss at step 270: 0.3709613084793091
train at step 280: 0.856249988079071
train loss at step 280: 0.3386796712875366
train at step 290: 0.7798742055892944
train loss at step 290: 0.40473470091819763
train at step 300: 0.7358490824699402
train loss at step 300: 0.4675706923007965
train at step 310: 0.831250011920929
train loss at step 310: 0.3567630648612976
train at step 320: 0.8616352081298828
train loss at step 320: 0.3137770891189575
train at step 330: 0.8679245114326477
train loss at step 330: 0.35194140672683716
train at step 340: 0.78125
train loss at step 340: 0.415543794631958
train at step 350: 0.698113203048706
train loss at step 350: 0.6426272988319397
train at step 360: 0.7735849022865295
train loss at step 360: 0.40173205733299255
train at step 370: 0.8812500238418579
train loss at step 370: 0.31525304913520813
train at step 380: 0.7924528121948242
train loss at step 380: 0.43628302216529846
train at step 390: 0.805031418800354
train loss at step 390: 0.39241358637809753
train at step 400: 0.875
train loss at step 400: 0.31750017404556274
train at step 410: 0.8742138147354126
train loss at step 410: 0.29456382989883423
train at step 420: 0.8742138147354126
train loss at step 420: 0.2731049060821533
train at step 430: 0.887499988079071
train loss at step 430: 0.299720823764801
train at step 440: 0.8742138147354126
train loss at step 440: 0.2623629868030548
train at step 450: 0.8238993883132935
train loss at step 450: 0.392265647649765
train at step 460: 0.78125
train loss at step 460: 0.4702916145324707
train at step 470: 0.8616352081298828
train loss at step 470: 0.31444650888442993
train at step 480: 0.8805031180381775
train loss at step 480: 0.2941947877407074
train at step 490: 0.887499988079071
train loss at step 490: 0.24003484845161438
train at step 500: 0.8742138147354126
train loss at step 500: 0.3123493194580078
train at step 510: 0.8427672982215881
train loss at step 510: 0.34717315435409546
train at step 520: 0.8687499761581421
train loss at step 520: 0.29689329862594604
train at step 530: 0.8553459048271179
train loss at step 530: 0.3190038204193115
train at step 540: 0.9245283007621765
train loss at step 540: 0.22987623512744904
train at step 550: 0.887499988079071
train loss at step 550: 0.27735334634780884
train at step 560: 0.9119496941566467
train loss at step 560: 0.24407824873924255
train at step 570: 0.8993710875511169
train loss at step 570: 0.262336790561676
train at step 580: 0.8812500238418579
train loss at step 580: 0.27400705218315125
train at step 590: 0.9056603908538818
train loss at step 590: 0.23615452647209167
train at step 600: 0.8805031180381775
train loss at step 600: 0.29079586267471313
train at step 610: 0.9496855139732361
train loss at step 610: 0.2208574116230011
train at step 620: 0.893750011920929
train loss at step 620: 0.23392708599567413
train at step 630: 0.9182389974594116
train loss at step 630: 0.24807937443256378
train at step 640: 0.9245283007621765
train loss at step 640: 0.23449495434761047
train at step 650: 0.8999999761581421
train loss at step 650: 0.26520222425460815
train at step 660: 0.8805031180381775
train loss at step 660: 0.26971158385276794
train at step 670: 0.9371069073677063
train loss at step 670: 0.20640870928764343
train at step 680: 0.90625
train loss at step 680: 0.23524586856365204
train at step 690: 0.8616352081298828
train loss at step 690: 0.27622175216674805
train at step 700: 0.8301886916160583
train loss at step 700: 0.356431245803833
train at step 710: 0.918749988079071
train loss at step 710: 0.21861132979393005
train at step 720: 0.9245283007621765
train loss at step 720: 0.20646628737449646
train at step 730: 0.9119496941566467
train loss at step 730: 0.23504209518432617
train at step 740: 0.9312499761581421
train loss at step 740: 0.1846965104341507
train at step 750: 0.8364779949188232
train loss at step 750: 0.3641451299190521
train at step 760: 0.8742138147354126
train loss at step 760: 0.2653923034667969
train at step 770: 0.9125000238418579
train loss at step 770: 0.22478076815605164
train at step 780: 0.8867924809455872
train loss at step 780: 0.22176429629325867
train at step 790: 0.8742138147354126
train loss at step 790: 0.25244441628456116
train at step 800: 0.887499988079071
train loss at step 800: 0.2635848820209503
train at step 810: 0.9371069073677063
train loss at step 810: 0.18897268176078796
train at step 820: 0.9433962106704712
train loss at step 820: 0.19500258564949036
train at step 830: 0.8687499761581421
train loss at step 830: 0.2878339886665344
train at step 840: 0.9308176040649414
train loss at step 840: 0.2102060765028
train at step 850: 0.8993710875511169
train loss at step 850: 0.24449391663074493
train at step 860: 0.8812500238418579
train loss at step 860: 0.24191626906394958
train at step 870: 0.8867924809455872
train loss at step 870: 0.26271674036979675
train at step 880: 0.8616352081298828
train loss at step 880: 0.2957018315792084
train at step 890: 0.90625
train loss at step 890: 0.2612367570400238
train at step 900: 0.849056601524353
train loss at step 900: 0.3362318277359009
train at step 910: 0.9182389974594116
train loss at step 910: 0.18676021695137024
train at step 920: 0.9375
train loss at step 920: 0.16264724731445312
train at step 930: 0.9308176040649414
train loss at step 930: 0.18537604808807373
train at step 940: 0.9622641801834106
train loss at step 940: 0.15948276221752167
train at step 950: 0.96875
train loss at step 950: 0.1624598205089569
train at step 960: 0.9371069073677063
train loss at step 960: 0.2097446173429489
train at step 970: 0.9433962106704712
train loss at step 970: 0.1688174456357956
train at step 980: 0.918749988079071
train loss at step 980: 0.21846838295459747
train at step 990: 0.9182389974594116
train loss at step 990: 0.2015753537416458
train at step 1000: 0.9245283007621765
train loss at step 1000: 0.18950369954109192
train at step 1010: 0.925000011920929
train loss at step 1010: 0.19270355999469757
train at step 1020: 0.8867924809455872
train loss at step 1020: 0.2650948166847229
train at step 1030: 0.8616352081298828
train loss at step 1030: 0.30530065298080444
train at step 1040: 0.9375
train loss at step 1040: 0.1693238615989685
train at step 1050: 0.9245283007621765
train loss at step 1050: 0.2070266455411911
train at step 1060: 0.849056601524353
train loss at step 1060: 0.2767952084541321
train at step 1070: 0.9125000238418579
train loss at step 1070: 0.1925535649061203
train at step 1080: 0.9371069073677063
train loss at step 1080: 0.19457650184631348
train at step 1090: 0.9496855139732361
train loss at step 1090: 0.17534196376800537
train at step 1100: 0.981249988079071
train loss at step 1100: 0.12275262922048569
train at step 1110: 0.9371069073677063
train loss at step 1110: 0.16450390219688416
train at step 1120: 0.9245283007621765
train loss at step 1120: 0.18576277792453766
train at step 1130: 0.893750011920929
train loss at step 1130: 0.2141343355178833
train at step 1140: 0.9371069073677063
train loss at step 1140: 0.18407154083251953
train at step 1150: 0.9182389974594116
train loss at step 1150: 0.1842392385005951
train at step 1160: 0.949999988079071
train loss at step 1160: 0.15231332182884216
train at step 1170: 0.9371069073677063
train loss at step 1170: 0.16525959968566895
train at step 1180: 0.9308176040649414
train loss at step 1180: 0.20891635119915009
train at step 1190: 0.9496855139732361
train loss at step 1190: 0.13685700297355652
train at step 1200: 0.949999988079071
train loss at step 1200: 0.17679712176322937
train at step 1210: 0.8679245114326477
train loss at step 1210: 0.3020009398460388
train at step 1220: 0.9245283007621765
train loss at step 1220: 0.15959110856056213
train at step 1230: 0.9312499761581421
train loss at step 1230: 0.1823509931564331
train at step 1240: 0.955974817276001
train loss at step 1240: 0.13379468023777008
train at step 1250: 0.9308176040649414
train loss at step 1250: 0.17887786030769348
train at step 1260: 0.96875
train loss at step 1260: 0.1165245994925499
train at step 1270: 0.9433962106704712
train loss at step 1270: 0.18133188784122467
train at step 1280: 0.9245283007621765
train loss at step 1280: 0.16565415263175964
train at step 1290: 0.949999988079071
train loss at step 1290: 0.12716178596019745
train at step 1300: 0.9371069073677063
train loss at step 1300: 0.18537724018096924
train at step 1310: 0.9685534834861755
train loss at step 1310: 0.12197576463222504
train at step 1320: 0.9624999761581421
train loss at step 1320: 0.12763063609600067
train at step 1330: 0.955974817276001
train loss at step 1330: 0.13313457369804382
train at step 1340: 0.9622641801834106
train loss at step 1340: 0.11807356029748917
train at step 1350: 0.9624999761581421
train loss at step 1350: 0.12443302571773529
train at step 1360: 0.9371069073677063
train loss at step 1360: 0.176023930311203
train at step 1370: 0.9685534834861755
train loss at step 1370: 0.11973927170038223
train at step 1380: 0.9375
train loss at step 1380: 0.167206808924675
train at step 1390: 0.9811320900917053
train loss at step 1390: 0.08173404633998871
train at step 1400: 0.9496855139732361
train loss at step 1400: 0.13987666368484497
train at step 1410: 0.9624999761581421
train loss at step 1410: 0.11806736141443253
train at step 1420: 0.9748427867889404
train loss at step 1420: 0.10322447866201401
train at step 1430: 0.9433962106704712
train loss at step 1430: 0.14824506640434265
train at step 1440: 0.956250011920929
train loss at step 1440: 0.10281245410442352
train at step 1450: 0.9874213933944702
train loss at step 1450: 0.07846830785274506
train at step 1460: 0.9622641801834106
train loss at step 1460: 0.13616470992565155
train at step 1470: 0.9624999761581421
train loss at step 1470: 0.10626973956823349
train at step 1480: 0.955974817276001
train loss at step 1480: 0.11376474797725677
train at step 1490: 0.9748427867889404
train loss at step 1490: 0.08844064176082611
train at step 1500: 0.96875
train loss at step 1500: 0.10806968063116074

train at step 1510: 0.643750011920929
train loss at step 1510: 1.0385091304779053
train at step 1520: 0.800000011920929
train loss at step 1520: 0.4319516718387604
train at step 1530: 0.887499988079071
train loss at step 1530: 0.21934428811073303
dev at step 1530: 0.5
New best on dev at step 1530: 0.5
dev loss at step 1530: 3.430704116821289
test at step 1530: 0.7905405163764954
test loss at step 1530: 1.4142502546310425
tp: 117, tn: 0, fp: 31, fn: 0
accuracy: 0.7905405405405406, precision: 0.7905405405405406, recall: 1.0, F1: 0.8830188679245283
specificity: 0.0, gmean: 0.0, mcc: 0 

train at step 1540: 0.9437500238418579
train loss at step 1540: 0.15445514023303986
train at step 1550: 0.9937499761581421
train loss at step 1550: 0.06509005278348923
train at step 1560: 0.96875
train loss at step 1560: 0.09042568504810333
dev at step 1560: 0.5
dev loss at step 1560: 6.901839733123779
test at step 1560: 0.7905405163764954
test loss at step 1560: 2.581742525100708
tp: 117, tn: 0, fp: 31, fn: 0
accuracy: 0.7905405405405406, precision: 0.7905405405405406, recall: 1.0, F1: 0.8830188679245283
specificity: 0.0, gmean: 0.0, mcc: 0 

train at step 1570: 0.956250011920929
train loss at step 1570: 0.10264796018600464
train at step 1580: 0.987500011920929
train loss at step 1580: 0.032012131065130234
train at step 1590: 1.0
train loss at step 1590: 0.02062511257827282
dev at step 1590: 0.5
dev loss at step 1590: 5.525389671325684
test at step 1590: 0.8040540814399719
test loss at step 1590: 1.965719223022461
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1600: 1.0
train loss at step 1600: 0.023275325074791908
train at step 1610: 1.0
train loss at step 1610: 0.011564558371901512
train at step 1620: 1.0
train loss at step 1620: 0.009136036969721317
dev at step 1620: 0.5
dev loss at step 1620: 6.905549049377441
test at step 1620: 0.7972972989082336
test loss at step 1620: 2.472334861755371
tp: 117, tn: 1, fp: 30, fn: 0
accuracy: 0.7972972972972973, precision: 0.7959183673469388, recall: 1.0, F1: 0.8863636363636364
specificity: 0.03225806451612903, gmean: 0.1796053020267749, mcc: 0.16023353595127843 

train at step 1630: 1.0
train loss at step 1630: 0.004838408436626196
train at step 1640: 1.0
train loss at step 1640: 0.004930821247398853
train at step 1650: 1.0
train loss at step 1650: 0.0043769413605332375
dev at step 1650: 0.5
dev loss at step 1650: 6.946374416351318
test at step 1650: 0.7972972989082336
test loss at step 1650: 2.467658281326294
tp: 117, tn: 1, fp: 30, fn: 0
accuracy: 0.7972972972972973, precision: 0.7959183673469388, recall: 1.0, F1: 0.8863636363636364
specificity: 0.03225806451612903, gmean: 0.1796053020267749, mcc: 0.16023353595127843 

train at step 1660: 1.0
train loss at step 1660: 0.0034751412458717823
train at step 1670: 1.0
train loss at step 1670: 0.002820029854774475
train at step 1680: 1.0
train loss at step 1680: 0.002823119517415762
dev at step 1680: 0.5
dev loss at step 1680: 7.584542751312256
test at step 1680: 0.7972972989082336
test loss at step 1680: 2.6996963024139404
tp: 117, tn: 1, fp: 30, fn: 0
accuracy: 0.7972972972972973, precision: 0.7959183673469388, recall: 1.0, F1: 0.8863636363636364
specificity: 0.03225806451612903, gmean: 0.1796053020267749, mcc: 0.16023353595127843 

train at step 1690: 1.0
train loss at step 1690: 0.0029988305177539587
train at step 1700: 1.0
train loss at step 1700: 0.0024851185735315084
train at step 1710: 1.0
train loss at step 1710: 0.0021410216577351093
dev at step 1710: 0.5
dev loss at step 1710: 7.42616605758667
test at step 1710: 0.8040540814399719
test loss at step 1710: 2.6225666999816895
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1720: 1.0
train loss at step 1720: 0.0018049913924187422
train at step 1730: 1.0
train loss at step 1730: 0.0015753671759739518
train at step 1740: 1.0
train loss at step 1740: 0.0015374734066426754
dev at step 1740: 0.5
dev loss at step 1740: 7.725184917449951
test at step 1740: 0.8040540814399719
test loss at step 1740: 2.7293412685394287
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1750: 1.0
train loss at step 1750: 0.0016383256297558546
train at step 1760: 1.0
train loss at step 1760: 0.0014147476758807898
train at step 1770: 1.0
train loss at step 1770: 0.0015616307500749826
dev at step 1770: 0.5
dev loss at step 1770: 7.90838623046875
test at step 1770: 0.8040540814399719
test loss at step 1770: 2.791841506958008
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1780: 1.0
train loss at step 1780: 0.0014527894090861082
train at step 1790: 1.0
train loss at step 1790: 0.0011978286784142256
train at step 1800: 1.0
train loss at step 1800: 0.0012768837623298168
dev at step 1800: 0.5
dev loss at step 1800: 7.947123050689697
test at step 1800: 0.8040540814399719
test loss at step 1800: 2.7993767261505127
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1810: 1.0
train loss at step 1810: 0.0012432679068297148
train at step 1820: 1.0
train loss at step 1820: 0.0010424595093354583
train at step 1830: 1.0
train loss at step 1830: 0.0009151586564257741
dev at step 1830: 0.5
dev loss at step 1830: 7.656140327453613
test at step 1830: 0.8040540814399719
test loss at step 1830: 2.679821014404297
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1840: 1.0
train loss at step 1840: 0.0008762308279983699
train at step 1850: 1.0
train loss at step 1850: 0.0007925443351268768
train at step 1860: 1.0
train loss at step 1860: 0.0008274175343103707
dev at step 1860: 0.5
dev loss at step 1860: 7.624144554138184
test at step 1860: 0.8040540814399719
test loss at step 1860: 2.662529706954956
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1870: 1.0
train loss at step 1870: 0.0007036227616481483
train at step 1880: 1.0
train loss at step 1880: 0.0007392254774458706
train at step 1890: 1.0
train loss at step 1890: 0.0006739060627296567
dev at step 1890: 0.5
dev loss at step 1890: 7.7621355056762695
test at step 1890: 0.8040540814399719
test loss at step 1890: 2.7112019062042236
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1900: 1.0
train loss at step 1900: 0.0006981709157116711
train at step 1910: 1.0
train loss at step 1910: 0.0006409551133401692
train at step 1920: 1.0
train loss at step 1920: 0.000664336490444839
dev at step 1920: 0.5
dev loss at step 1920: 7.686886787414551
test at step 1920: 0.8040540814399719
test loss at step 1920: 2.6786980628967285
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1930: 1.0
train loss at step 1930: 0.0005717534222640097
train at step 1940: 1.0
train loss at step 1940: 0.0006099276361055672
train at step 1950: 1.0
train loss at step 1950: 0.0005599618307314813
dev at step 1950: 0.5
dev loss at step 1950: 7.825139045715332
test at step 1950: 0.8040540814399719
test loss at step 1950: 2.728304386138916
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1960: 1.0
train loss at step 1960: 0.0005820026271976531
train at step 1970: 1.0
train loss at step 1970: 0.0005362044321373105
train at step 1980: 1.0
train loss at step 1980: 0.000548696843907237
dev at step 1980: 0.5
dev loss at step 1980: 7.7624335289001465
test at step 1980: 0.8040540814399719
test loss at step 1980: 2.701267719268799
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 1990: 1.0
train loss at step 1990: 0.0004812544211745262
train at step 2000: 1.0
train loss at step 2000: 0.0005179328145459294
train at step 2010: 1.0
train loss at step 2010: 0.0004760824958793819
dev at step 2010: 0.5
dev loss at step 2010: 7.867719650268555
test at step 2010: 0.8040540814399719
test loss at step 2010: 2.738767147064209
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2020: 1.0
train loss at step 2020: 0.0004956268821842968
train at step 2030: 1.0
train loss at step 2030: 0.00045825951383449137
train at step 2040: 1.0
train loss at step 2040: 0.0004665536689572036
dev at step 2040: 0.5
dev loss at step 2040: 7.831963539123535
test at step 2040: 0.8040540814399719
test loss at step 2040: 2.722512722015381
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2050: 1.0
train loss at step 2050: 0.00041438746848143637
train at step 2060: 1.0
train loss at step 2060: 0.0004478798364289105
train at step 2070: 1.0
train loss at step 2070: 0.0004111354355700314
dev at step 2070: 0.5
dev loss at step 2070: 7.908838272094727
test at step 2070: 0.8040540814399719
test loss at step 2070: 2.749498128890991
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2080: 1.0
train loss at step 2080: 0.00042958889389410615
train at step 2090: 1.0
train loss at step 2090: 0.00039827064028941095
train at step 2100: 1.0
train loss at step 2100: 0.0004056532052345574
dev at step 2100: 0.5
dev loss at step 2100: 7.888659477233887
test at step 2100: 0.8040540814399719
test loss at step 2100: 2.7395427227020264
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2110: 1.0
train loss at step 2110: 0.0003619901544880122
train at step 2120: 1.0
train loss at step 2120: 0.0003928266523871571
train at step 2130: 1.0
train loss at step 2130: 0.0003600031486712396
dev at step 2130: 0.5
dev loss at step 2130: 7.948681354522705
test at step 2130: 0.8040540814399719
test loss at step 2130: 2.7603518962860107
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2140: 1.0
train loss at step 2140: 0.00037748905015178025
train at step 2150: 1.0
train loss at step 2150: 0.0003506627690512687
train at step 2160: 1.0
train loss at step 2160: 0.0003579651820473373
dev at step 2160: 0.5
dev loss at step 2160: 7.937173366546631
test at step 2160: 0.8040540814399719
test loss at step 2160: 2.753969430923462
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2170: 1.0
train loss at step 2170: 0.0003198327904101461
train at step 2180: 1.0
train loss at step 2180: 0.00034848955692723393
train at step 2190: 1.0
train loss at step 2190: 0.0003186286776326597
dev at step 2190: 0.5
dev loss at step 2190: 7.986408710479736
test at step 2190: 0.8040540814399719
test loss at step 2190: 2.7708656787872314
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2200: 1.0
train loss at step 2200: 0.00033528392668813467
train at step 2210: 1.0
train loss at step 2210: 0.0003119248722214252
train at step 2220: 1.0
train loss at step 2220: 0.0003192711155861616
dev at step 2220: 0.5
dev loss at step 2220: 7.980832099914551
test at step 2220: 0.8040540814399719
test loss at step 2220: 2.766950845718384
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2230: 1.0
train loss at step 2230: 0.0002853175101336092
train at step 2240: 1.0
train loss at step 2240: 0.00031196122290566564
train at step 2250: 1.0
train loss at step 2250: 0.000284375564660877
dev at step 2250: 0.5
dev loss at step 2250: 8.022937774658203
test at step 2250: 0.8040540814399719
test loss at step 2250: 2.7812955379486084
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2260: 1.0
train loss at step 2260: 0.00030044146114960313
train at step 2270: 1.0
train loss at step 2270: 0.0002797950874082744
train at step 2280: 1.0
train loss at step 2280: 0.0002870760508812964
dev at step 2280: 0.5
dev loss at step 2280: 8.022015571594238
test at step 2280: 0.8040540814399719
test loss at step 2280: 2.7793221473693848
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2290: 1.0
train loss at step 2290: 0.0002566464536357671
train at step 2300: 1.0
train loss at step 2300: 0.0002812979801092297
train at step 2310: 1.0
train loss at step 2310: 0.0002555620449129492
dev at step 2310: 0.5
dev loss at step 2310: 8.059406280517578
test at step 2310: 0.8040540814399719
test loss at step 2310: 2.7920074462890625
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2320: 1.0
train loss at step 2320: 0.00027122668689116836
train at step 2330: 1.0
train loss at step 2330: 0.0002527031465433538
train at step 2340: 1.0
train loss at step 2340: 0.0002597615239210427
dev at step 2340: 0.5
dev loss at step 2340: 8.062346458435059
test at step 2340: 0.8040540814399719
test loss at step 2340: 2.791640281677246
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2350: 1.0
train loss at step 2350: 0.00023252754181157798
train at step 2360: 1.0
train loss at step 2360: 0.0002551308134570718
train at step 2370: 1.0
train loss at step 2370: 0.00023103812418412417
dev at step 2370: 0.5
dev loss at step 2370: 8.096565246582031
test at step 2370: 0.8040540814399719
test loss at step 2370: 2.803234577178955
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2380: 1.0
train loss at step 2380: 0.00024639483308419585
train at step 2390: 1.0
train loss at step 2390: 0.00022955227177590132
train at step 2400: 1.0
train loss at step 2400: 0.00023626834445167333
dev at step 2400: 0.5
dev loss at step 2400: 8.1026611328125
test at step 2400: 0.8040540814399719
test loss at step 2400: 2.8041820526123047
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2410: 1.0
train loss at step 2410: 0.0002119497221428901
train at step 2420: 1.0
train loss at step 2420: 0.00023251624952536076
train at step 2430: 1.0
train loss at step 2430: 0.00020998479158151895
dev at step 2430: 0.5
dev loss at step 2430: 8.134627342224121
test at step 2430: 0.8040540814399719
test loss at step 2430: 2.815016984939575
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2440: 1.0
train loss at step 2440: 0.00022501125931739807
train at step 2450: 1.0
train loss at step 2450: 0.00020955942454747856
train at step 2460: 1.0
train loss at step 2460: 0.00021584684145636857
dev at step 2460: 0.5
dev loss at step 2460: 8.143112182617188
test at step 2460: 0.8040540814399719
test loss at step 2460: 2.8169686794281006
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2470: 1.0
train loss at step 2470: 0.00019419589079916477
train at step 2480: 1.0
train loss at step 2480: 0.00021279227803461254
train at step 2490: 1.0
train loss at step 2490: 0.00019177290960215032
dev at step 2490: 0.5
dev loss at step 2490: 8.173294067382812
test at step 2490: 0.8040540814399719
test loss at step 2490: 2.8272080421447754
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2500: 1.0
train loss at step 2500: 0.00020641300943680108
train at step 2510: 1.0
train loss at step 2510: 0.000192142091691494
train at step 2520: 1.0
train loss at step 2520: 0.00019796141714323312
dev at step 2520: 0.5
dev loss at step 2520: 8.183460235595703
test at step 2520: 0.8040540814399719
test loss at step 2520: 2.829878568649292
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2530: 1.0
train loss at step 2530: 0.00017867665155790746
train at step 2540: 1.0
train loss at step 2540: 0.00019548037380445749
train at step 2550: 1.0
train loss at step 2550: 0.0001759152510203421
dev at step 2550: 0.5
dev loss at step 2550: 8.212034225463867
test at step 2550: 0.8040540814399719
test loss at step 2550: 2.8395774364471436
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2560: 1.0
train loss at step 2560: 0.00019007825176231563
train at step 2570: 1.0
train loss at step 2570: 0.00017686397768557072
train at step 2580: 1.0
train loss at step 2580: 0.00018220714991912246
dev at step 2580: 0.5
dev loss at step 2580: 8.223233222961426
test at step 2580: 0.8040540814399719
test loss at step 2580: 2.842707633972168
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2590: 1.0
train loss at step 2590: 0.00016499121556989849
train at step 2600: 1.0
train loss at step 2600: 0.00018019179697148502
train at step 2610: 1.0
train loss at step 2610: 0.00016200539539568126
dev at step 2610: 0.5
dev loss at step 2610: 8.250290870666504
test at step 2610: 0.8040540814399719
test loss at step 2610: 2.851891040802002
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2620: 1.0
train loss at step 2620: 0.000175625566043891
train at step 2630: 1.0
train loss at step 2630: 0.0001633698120713234
train at step 2640: 1.0
train loss at step 2640: 0.0001682497386354953
dev at step 2640: 0.5
dev loss at step 2640: 8.262069702148438
test at step 2640: 0.8040540814399719
test loss at step 2640: 2.8552985191345215
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2650: 1.0
train loss at step 2650: 0.0001528197608422488
train at step 2660: 1.0
train loss at step 2660: 0.00016662174311932176
train at step 2670: 1.0
train loss at step 2670: 0.00014972529606893659
dev at step 2670: 0.5
dev loss at step 2670: 8.287637710571289
test at step 2670: 0.8040540814399719
test loss at step 2670: 2.8639678955078125
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2680: 1.0
train loss at step 2680: 0.00016277610848192126
train at step 2690: 1.0
train loss at step 2690: 0.00015139042807277292
train at step 2700: 1.0
train loss at step 2700: 0.0001558268122607842
dev at step 2700: 0.5
dev loss at step 2700: 8.299702644348145
test at step 2700: 0.8040540814399719
test loss at step 2700: 2.8675355911254883
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2710: 1.0
train loss at step 2710: 0.0001419504696968943
train at step 2720: 1.0
train loss at step 2720: 0.00015452790830750018
train at step 2730: 1.0
train loss at step 2730: 0.00013881109771318734
dev at step 2730: 0.5
dev loss at step 2730: 8.323881149291992
test at step 2730: 0.8040540814399719
test loss at step 2730: 2.8757216930389404
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2740: 1.0
train loss at step 2740: 0.00015126884682103992
train at step 2750: 1.0
train loss at step 2750: 0.0001406789233442396
train at step 2760: 1.0
train loss at step 2760: 0.0001447139511583373
dev at step 2760: 0.5
dev loss at step 2760: 8.336020469665527
test at step 2760: 0.8040540814399719
test loss at step 2760: 2.8793601989746094
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2770: 1.0
train loss at step 2770: 0.00013216526713222265
train at step 2780: 1.0
train loss at step 2780: 0.0001436923339497298
train at step 2790: 1.0
train loss at step 2790: 0.00012905609037261456
dev at step 2790: 0.5
dev loss at step 2790: 8.358882904052734
test at step 2790: 0.8040540814399719
test loss at step 2790: 2.887086868286133
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2800: 1.0
train loss at step 2800: 0.00014092677156440914
train at step 2810: 1.0
train loss at step 2810: 0.00013106655387673527
train at step 2820: 1.0
train loss at step 2820: 0.00013473052240442485
dev at step 2820: 0.5
dev loss at step 2820: 8.371021270751953
test at step 2820: 0.8040540814399719
test loss at step 2820: 2.8907642364501953
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2830: 1.0
train loss at step 2830: 0.0001233340590260923
train at step 2840: 1.0
train loss at step 2840: 0.00013393656990956515
train at step 2850: 1.0
train loss at step 2850: 0.00012028778292005882
dev at step 2850: 0.5
dev loss at step 2850: 8.392666816711426
test at step 2850: 0.8040540814399719
test loss at step 2850: 2.898064374923706
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2860: 1.0
train loss at step 2860: 0.00013158778892830014
train at step 2870: 1.0
train loss at step 2870: 0.00012239183706697077
train at step 2880: 1.0
train loss at step 2880: 0.00012572333798743784
dev at step 2880: 0.5
dev loss at step 2880: 8.404720306396484
test at step 2880: 0.8040540814399719
test loss at step 2880: 2.901742935180664
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2890: 1.0
train loss at step 2890: 0.00011533706856425852
train at step 2900: 1.0
train loss at step 2900: 0.00012513269030023366
train at step 2910: 1.0
train loss at step 2910: 0.00011238050501560792
dev at step 2910: 0.5
dev loss at step 2910: 8.425270080566406
test at step 2910: 0.8040540814399719
test loss at step 2910: 2.9086575508117676
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2920: 1.0
train loss at step 2920: 0.0001231276837643236
train at step 2930: 1.0
train loss at step 2930: 0.00011453281331341714
train at step 2940: 1.0
train loss at step 2940: 0.00011756224557757378
dev at step 2940: 0.5
dev loss at step 2940: 8.437294960021973
test at step 2940: 0.8040540814399719
test loss at step 2940: 2.912356376647949
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2950: 1.0
train loss at step 2950: 0.00010805528290802613
train at step 2960: 1.0
train loss at step 2960: 0.00011714305583154783
train at step 2970: 1.0
train loss at step 2970: 0.00010520927753532305
dev at step 2970: 0.5
dev loss at step 2970: 8.456750869750977
test at step 2970: 0.8040540814399719
test loss at step 2970: 2.9188852310180664
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 2980: 1.0
train loss at step 2980: 0.00011542219726834446
train at step 2990: 1.0
train loss at step 2990: 0.00010738611308624968
train at step 3000: 1.0
train loss at step 3000: 0.00011015731433872133
dev at step 3000: 0.5
dev loss at step 3000: 8.468685150146484
test at step 3000: 0.8040540814399719
test loss at step 3000: 2.9225759506225586
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3010: 1.0
train loss at step 3010: 0.00010141282109543681
train at step 3020: 1.0
train loss at step 3020: 0.00010987171117449179
train at step 3030: 1.0
train loss at step 3030: 9.86773957265541e-05
dev at step 3030: 0.5
dev loss at step 3030: 8.487222671508789
test at step 3030: 0.8040540814399719
test loss at step 3030: 2.9287819862365723
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3040: 1.0
train loss at step 3040: 0.0001083947136066854
train at step 3050: 1.0
train loss at step 3050: 0.00010086163820233196
train at step 3060: 1.0
train loss at step 3060: 0.00010339097207179293
dev at step 3060: 0.5
dev loss at step 3060: 8.499104499816895
test at step 3060: 0.8040540814399719
test loss at step 3060: 2.932478427886963
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3070: 1.0
train loss at step 3070: 9.533827687846497e-05
train at step 3080: 1.0
train loss at step 3080: 0.00010322562593501061
train at step 3090: 1.0
train loss at step 3090: 9.271271846955642e-05
dev at step 3090: 0.5
dev loss at step 3090: 8.516753196716309
test at step 3090: 0.8040540814399719
test loss at step 3090: 2.9383704662323
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3100: 1.0
train loss at step 3100: 0.00010195524373557419
train at step 3110: 1.0
train loss at step 3110: 9.488355135545135e-05
train at step 3120: 1.0
train loss at step 3120: 9.720298112370074e-05
dev at step 3120: 0.5
dev loss at step 3120: 8.528570175170898
test at step 3120: 0.8040540814399719
test loss at step 3120: 2.942065715789795
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3130: 1.0
train loss at step 3130: 8.975497621577233e-05
train at step 3140: 1.0
train loss at step 3140: 9.713636245578527e-05
train at step 3150: 1.0
train loss at step 3150: 8.725198858883232e-05
dev at step 3150: 0.5
dev loss at step 3150: 8.545433044433594
test at step 3150: 0.8040540814399719
test loss at step 3150: 2.9476804733276367
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3160: 1.0
train loss at step 3160: 9.60457618930377e-05
train at step 3170: 1.0
train loss at step 3170: 8.939675899455324e-05
train at step 3180: 1.0
train loss at step 3180: 9.15352939045988e-05
dev at step 3180: 0.5
dev loss at step 3180: 8.557197570800781
test at step 3180: 0.8040540814399719
test loss at step 3180: 2.9513769149780273
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3190: 1.0
train loss at step 3190: 8.462947880616412e-05
train at step 3200: 1.0
train loss at step 3200: 9.154067083727568e-05
train at step 3210: 1.0
train loss at step 3210: 8.22274960228242e-05
dev at step 3210: 0.5
dev loss at step 3210: 8.573294639587402
test at step 3210: 0.8040540814399719
test loss at step 3210: 2.956721305847168
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3220: 1.0
train loss at step 3220: 9.060224692802876e-05
train at step 3230: 1.0
train loss at step 3230: 8.434174378635362e-05
train at step 3240: 1.0
train loss at step 3240: 8.630978118162602e-05
dev at step 3240: 0.5
dev loss at step 3240: 8.585054397583008
test at step 3240: 0.8040540814399719
test loss at step 3240: 2.960435390472412
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3250: 1.0
train loss at step 3250: 7.988807919900864e-05
train at step 3260: 1.0
train loss at step 3260: 8.638272993266582e-05
train at step 3270: 1.0
train loss at step 3270: 7.759235450066626e-05
dev at step 3270: 0.5
dev loss at step 3270: 8.600422859191895
test at step 3270: 0.8040540814399719
test loss at step 3270: 2.965522050857544
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3280: 1.0
train loss at step 3280: 8.557412365917116e-05
train at step 3290: 1.0
train loss at step 3290: 7.966641715029255e-05
train at step 3300: 1.0
train loss at step 3300: 8.149522182065994e-05
dev at step 3300: 0.5
dev loss at step 3300: 8.612128257751465
test at step 3300: 0.8040540814399719
test loss at step 3300: 2.9692325592041016
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3310: 1.0
train loss at step 3310: 7.55002984078601e-05
train at step 3320: 1.0
train loss at step 3320: 8.16216052044183e-05
train at step 3330: 1.0
train loss at step 3330: 7.332277164096013e-05
dev at step 3330: 0.5
dev loss at step 3330: 8.626899719238281
test at step 3330: 0.8040540814399719
test loss at step 3330: 2.9741101264953613
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3340: 1.0
train loss at step 3340: 8.092565985862166e-05
train at step 3350: 1.0
train loss at step 3350: 7.534248288720846e-05
train at step 3360: 1.0
train loss at step 3360: 7.7032033004798e-05
dev at step 3360: 0.5
dev loss at step 3360: 8.638618469238281
test at step 3360: 0.8040540814399719
test loss at step 3360: 2.977842092514038
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3370: 1.0
train loss at step 3370: 7.144307164708152e-05
train at step 3380: 1.0
train loss at step 3380: 7.720520079601556e-05
train at step 3390: 1.0
train loss at step 3390: 6.935842975508422e-05
dev at step 3390: 0.5
dev loss at step 3390: 8.652769088745117
test at step 3390: 0.8040540814399719
test loss at step 3390: 2.9825003147125244
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3400: 1.0
train loss at step 3400: 7.660550181753933e-05
train at step 3410: 1.0
train loss at step 3410: 7.133423059713095e-05
train at step 3420: 1.0
train loss at step 3420: 7.289867789950222e-05
dev at step 3420: 0.5
dev loss at step 3420: 8.664461135864258
test at step 3420: 0.8040540814399719
test loss at step 3420: 2.9862372875213623
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3430: 1.0
train loss at step 3430: 6.766502337995917e-05
train at step 3440: 1.0
train loss at step 3440: 7.311119406949729e-05
train at step 3450: 1.0
train loss at step 3450: 6.568001117557287e-05
dev at step 3450: 0.5
dev loss at step 3450: 8.678048133850098
test at step 3450: 0.8040540814399719
test loss at step 3450: 2.9906959533691406
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3460: 1.0
train loss at step 3460: 7.259506674017757e-05
train at step 3470: 1.0
train loss at step 3470: 6.760146789019927e-05
train at step 3480: 1.0
train loss at step 3480: 6.906165071995929e-05
dev at step 3480: 0.5
dev loss at step 3480: 8.689780235290527
test at step 3480: 0.8040540814399719
test loss at step 3480: 2.994462013244629
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3490: 1.0
train loss at step 3490: 6.416170799639076e-05
train at step 3500: 1.0
train loss at step 3500: 6.930533709237352e-05
train at step 3510: 1.0
train loss at step 3510: 6.226291588973254e-05
dev at step 3510: 0.5
dev loss at step 3510: 8.702831268310547
test at step 3510: 0.8040540814399719
test loss at step 3510: 2.998732328414917
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3520: 1.0
train loss at step 3520: 6.886233313707635e-05
train at step 3530: 1.0
train loss at step 3530: 6.4132284023799e-05
train at step 3540: 1.0
train loss at step 3540: 6.549117097165436e-05
dev at step 3540: 0.5
dev loss at step 3540: 8.714556694030762
test at step 3540: 0.8040540814399719
test loss at step 3540: 3.002509117126465
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3550: 1.0
train loss at step 3550: 6.0887705330969766e-05
train at step 3560: 1.0
train loss at step 3560: 6.575859879376367e-05
train at step 3570: 1.0
train loss at step 3570: 5.908038656343706e-05
dev at step 3570: 0.5
dev loss at step 3570: 8.727109909057617
test at step 3570: 0.8040540814399719
test loss at step 3570: 3.0066027641296387
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3580: 1.0
train loss at step 3580: 6.538424349855632e-05
train at step 3590: 1.0
train loss at step 3590: 6.090211172704585e-05
train at step 3600: 1.0
train loss at step 3600: 6.216716428752989e-05
dev at step 3600: 0.5
dev loss at step 3600: 8.738836288452148
test at step 3600: 0.8040540814399719
test loss at step 3600: 3.010392904281616
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3610: 1.0
train loss at step 3610: 5.783484084531665e-05
train at step 3620: 1.0
train loss at step 3620: 6.245386612135917e-05
train at step 3630: 1.0
train loss at step 3630: 5.610933294519782e-05
dev at step 3630: 0.5
dev loss at step 3630: 8.750930786132812
test at step 3630: 0.8040540814399719
test loss at step 3630: 3.0143258571624756
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3640: 1.0
train loss at step 3640: 6.21347498963587e-05
train at step 3650: 1.0
train loss at step 3650: 5.7872985053109005e-05
train at step 3660: 1.0
train loss at step 3660: 5.9059828345198184e-05
dev at step 3660: 0.5
dev loss at step 3660: 8.762651443481445
test at step 3660: 0.8040540814399719
test loss at step 3660: 3.018125295639038
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3670: 1.0
train loss at step 3670: 5.497482925420627e-05
train at step 3680: 1.0
train loss at step 3680: 5.936135494266637e-05
train at step 3690: 1.0
train loss at step 3690: 5.332740693120286e-05
dev at step 3690: 0.5
dev loss at step 3690: 8.77431869506836
test at step 3690: 0.8040540814399719
test loss at step 3690: 3.021906852722168
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3700: 1.0
train loss at step 3700: 5.9084046370116994e-05
train at step 3710: 1.0
train loss at step 3710: 5.503969805431552e-05
train at step 3720: 1.0
train loss at step 3720: 5.615056215901859e-05
dev at step 3720: 0.5
dev loss at step 3720: 8.786101341247559
test at step 3720: 0.8040540814399719
test loss at step 3720: 3.0257408618927
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3730: 1.0
train loss at step 3730: 5.230469469097443e-05
train at step 3740: 1.0
train loss at step 3740: 5.646470162901096e-05
train at step 3750: 1.0
train loss at step 3750: 5.072346539236605e-05
dev at step 3750: 0.5
dev loss at step 3750: 8.797322273254395
test at step 3750: 0.8040540814399719
test loss at step 3750: 3.0293643474578857
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3760: 1.0
train loss at step 3760: 5.623365723295137e-05
train at step 3770: 1.0
train loss at step 3770: 5.2387360483407974e-05
train at step 3780: 1.0
train loss at step 3780: 5.34289501956664e-05
dev at step 3780: 0.5
dev loss at step 3780: 8.809137344360352
test at step 3780: 0.8040540814399719
test loss at step 3780: 3.033219575881958
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3790: 1.0
train loss at step 3790: 4.979540244676173e-05
train at step 3800: 1.0
train loss at step 3800: 5.3752719395561144e-05
train at step 3810: 1.0
train loss at step 3810: 4.8287070967489854e-05
dev at step 3810: 0.5
dev loss at step 3810: 8.81991958618164
test at step 3810: 0.8040540814399719
test loss at step 3810: 3.0366873741149902
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3820: 1.0
train loss at step 3820: 5.3556013881461695e-05
train at step 3830: 1.0
train loss at step 3830: 4.989513035980053e-05
train at step 3840: 1.0
train loss at step 3840: 5.0871905841631815e-05
dev at step 3840: 0.5
dev loss at step 3840: 8.831787109375
test at step 3840: 0.8040540814399719
test loss at step 3840: 3.04057240486145
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3850: 1.0
train loss at step 3850: 4.743801400763914e-05
train at step 3860: 1.0
train loss at step 3860: 5.119638080941513e-05
train at step 3870: 1.0
train loss at step 3870: 4.599888052325696e-05
dev at step 3870: 0.5
dev loss at step 3870: 8.842215538024902
test at step 3870: 0.8040540814399719
test loss at step 3870: 3.0439155101776123
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3880: 1.0
train loss at step 3880: 5.104816591483541e-05
train at step 3890: 1.0
train loss at step 3890: 4.7554814955219626e-05
train at step 3900: 1.0
train loss at step 3900: 4.8474979848833755e-05
dev at step 3900: 0.5
dev loss at step 3900: 8.854073524475098
test at step 3900: 0.8040540814399719
test loss at step 3900: 3.0478057861328125
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3910: 1.0
train loss at step 3910: 4.523031384451315e-05
train at step 3920: 1.0
train loss at step 3920: 4.880909182247706e-05
train at step 3930: 1.0
train loss at step 3930: 4.384099520393647e-05
dev at step 3930: 0.5
dev loss at step 3930: 8.864192962646484
test at step 3930: 0.8040540814399719
test loss at step 3930: 3.051041841506958
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3940: 1.0
train loss at step 3940: 4.86803000967484e-05
train at step 3950: 1.0
train loss at step 3950: 4.53567408840172e-05
train at step 3960: 1.0
train loss at step 3960: 4.622550477506593e-05
dev at step 3960: 0.5
dev loss at step 3960: 8.87608528137207
test at step 3960: 0.8040540814399719
test loss at step 3960: 3.054953098297119
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 3970: 1.0
train loss at step 3970: 4.314324542065151e-05
train at step 3980: 1.0
train loss at step 3980: 4.655063821701333e-05
train at step 3990: 1.0
train loss at step 3990: 4.182463453616947e-05
dev at step 3990: 0.5
dev loss at step 3990: 8.885809898376465
test at step 3990: 0.8040540814399719
test loss at step 3990: 3.0580477714538574
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4000: 1.0
train loss at step 4000: 4.6449469664366916e-05
train at step 4010: 1.0
train loss at step 4010: 4.327856004238129e-05
train at step 4020: 1.0
train loss at step 4020: 4.4098153011873364e-05
dev at step 4020: 0.5
dev loss at step 4020: 8.897801399230957
test at step 4020: 0.8040540814399719
test loss at step 4020: 3.062004327774048
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4030: 1.0
train loss at step 4030: 4.117681601201184e-05
train at step 4040: 1.0
train loss at step 4040: 4.4426989916246384e-05
train at step 4050: 1.0
train loss at step 4050: 3.991400444647297e-05
dev at step 4050: 0.5
dev loss at step 4050: 8.90721321105957
test at step 4050: 0.8040540814399719
test loss at step 4050: 3.0649893283843994
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4060: 1.0
train loss at step 4060: 4.434672518982552e-05
train at step 4070: 1.0
train loss at step 4070: 4.132847971050069e-05
train at step 4080: 1.0
train loss at step 4080: 4.209517646813765e-05
dev at step 4080: 0.5
dev loss at step 4080: 8.919178009033203
test at step 4080: 0.8040540814399719
test loss at step 4080: 3.068942070007324
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4090: 1.0
train loss at step 4090: 3.9313155866693705e-05
train at step 4100: 1.0
train loss at step 4100: 4.242770228302106e-05
train at step 4110: 1.0
train loss at step 4110: 3.81128593289759e-05
dev at step 4110: 0.5
dev loss at step 4110: 8.928339004516602
test at step 4110: 0.8040540814399719
test loss at step 4110: 3.071840286254883
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4120: 1.0
train loss at step 4120: 4.2360152292530984e-05
train at step 4130: 1.0
train loss at step 4130: 3.94707421946805e-05
train at step 4140: 1.0
train loss at step 4140: 4.020465348730795e-05
dev at step 4140: 0.5
dev loss at step 4140: 8.940370559692383
test at step 4140: 0.8040540814399719
test loss at step 4140: 3.0758261680603027
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4150: 1.0
train loss at step 4150: 3.7570152926491573e-05
train at step 4160: 1.0
train loss at step 4160: 4.05311984650325e-05
train at step 4170: 1.0
train loss at step 4170: 3.640704744611867e-05
dev at step 4170: 0.5
dev loss at step 4170: 8.949226379394531
test at step 4170: 0.8040540814399719
test loss at step 4170: 3.07861590385437
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4180: 1.0
train loss at step 4180: 4.048455230076797e-05
train at step 4190: 1.0
train loss at step 4190: 3.7722486013080925e-05
train at step 4200: 1.0
train loss at step 4200: 3.841765646939166e-05
dev at step 4200: 0.5
dev loss at step 4200: 8.961258888244629
test at step 4200: 0.8040540814399719
test loss at step 4200: 3.082608938217163
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4210: 1.0
train loss at step 4210: 3.591949280234985e-05
train at step 4220: 1.0
train loss at step 4220: 3.8740454328944907e-05
train at step 4230: 1.0
train loss at step 4230: 3.480401574051939e-05
dev at step 4230: 0.5
dev loss at step 4230: 8.96981143951416
test at step 4230: 0.8040540814399719
test loss at step 4230: 3.085292100906372
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4240: 1.0
train loss at step 4240: 3.871247099596076e-05
train at step 4250: 1.0
train loss at step 4250: 3.6074772651772946e-05
train at step 4260: 1.0
train loss at step 4260: 3.673194441944361e-05
dev at step 4260: 0.5
dev loss at step 4260: 8.981908798217773
test at step 4260: 0.8040540814399719
test loss at step 4260: 3.089315414428711
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4270: 1.0
train loss at step 4270: 3.434926475165412e-05
train at step 4280: 1.0
train loss at step 4280: 3.705472772708163e-05
train at step 4290: 1.0
train loss at step 4290: 3.3285141398664564e-05
dev at step 4290: 0.5
dev loss at step 4290: 8.990214347839355
test at step 4290: 0.8040540814399719
test loss at step 4290: 3.091912031173706
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4300: 1.0
train loss at step 4300: 3.704092887346633e-05
train at step 4310: 1.0
train loss at step 4310: 3.4510470868553966e-05
train at step 4320: 1.0
train loss at step 4320: 3.513189221848734e-05
dev at step 4320: 0.5
dev loss at step 4320: 9.00232982635498
test at step 4320: 0.8040540814399719
test loss at step 4320: 3.0959484577178955
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4330: 1.0
train loss at step 4330: 3.2869153073988855e-05
train at step 4340: 1.0
train loss at step 4340: 3.54516705556307e-05
train at step 4350: 1.0
train loss at step 4350: 3.184373053954914e-05
dev at step 4350: 0.5
dev loss at step 4350: 9.010313034057617
test at step 4350: 0.8040540814399719
test loss at step 4350: 3.0984296798706055
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4360: 1.0
train loss at step 4360: 3.544684295775369e-05
train at step 4370: 1.0
train loss at step 4370: 3.303033736301586e-05
train at step 4380: 1.0
train loss at step 4380: 3.362418647157028e-05
dev at step 4380: 0.5
dev loss at step 4380: 9.022501945495605
test at step 4380: 0.8040540814399719
test loss at step 4380: 3.102499008178711
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4390: 1.0
train loss at step 4390: 3.146575181744993e-05
train at step 4400: 1.0
train loss at step 4400: 3.3935757528524846e-05
train at step 4410: 1.0
train loss at step 4410: 3.0483502996503375e-05
dev at step 4410: 0.5
dev loss at step 4410: 9.030327796936035
test at step 4410: 0.8040540814399719
test loss at step 4410: 3.1049258708953857
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4420: 1.0
train loss at step 4420: 3.394436862436123e-05
train at step 4430: 1.0
train loss at step 4430: 3.16269179165829e-05
train at step 4440: 1.0
train loss at step 4440: 3.218946949345991e-05
dev at step 4440: 0.5
dev loss at step 4440: 9.042465209960938
test at step 4440: 0.8040540814399719
test loss at step 4440: 3.1089818477630615
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4450: 1.0
train loss at step 4450: 3.0135342967696488e-05
train at step 4460: 1.0
train loss at step 4460: 3.249432484153658e-05
train at step 4470: 1.0
train loss at step 4470: 2.9191054636612535e-05
dev at step 4470: 0.5
dev loss at step 4470: 9.050106048583984
test at step 4470: 0.8040540814399719
test loss at step 4470: 3.1113455295562744
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4480: 1.0
train loss at step 4480: 3.251264206483029e-05
train at step 4490: 1.0
train loss at step 4490: 3.0292761948658153e-05
train at step 4500: 1.0
train loss at step 4500: 3.082402326981537e-05
dev at step 4500: 0.5
dev loss at step 4500: 9.062256813049316
test at step 4500: 0.8040540814399719
test loss at step 4500: 3.1154110431671143
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4510: 1.0
train loss at step 4510: 2.8860793463536538e-05
train at step 4520: 1.0
train loss at step 4520: 3.112960985163227e-05
train at step 4530: 1.0
train loss at step 4530: 2.795744512695819e-05
dev at step 4530: 0.5
dev loss at step 4530: 9.069664001464844
test at step 4530: 0.8040540814399719
test loss at step 4530: 3.117692470550537
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4540: 1.0
train loss at step 4540: 3.114869832643308e-05
train at step 4550: 1.0
train loss at step 4550: 2.9029364668531343e-05
train at step 4560: 1.0
train loss at step 4560: 2.953305738628842e-05
dev at step 4560: 0.5
dev loss at step 4560: 9.081923484802246
test at step 4560: 0.8040540814399719
test loss at step 4560: 3.1218039989471436
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4570: 1.0
train loss at step 4570: 2.7655503799906e-05
train at step 4580: 1.0
train loss at step 4580: 2.983193007821683e-05
train at step 4590: 1.0
train loss at step 4590: 2.6790870833792724e-05
dev at step 4590: 0.5
dev loss at step 4590: 9.089069366455078
test at step 4590: 0.8040540814399719
test loss at step 4590: 3.123990774154663
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4600: 1.0
train loss at step 4600: 2.9862960218451917e-05
train at step 4610: 1.0
train loss at step 4610: 2.7824065909953788e-05
train at step 4620: 1.0
train loss at step 4620: 2.8307640604907647e-05
dev at step 4620: 0.5
dev loss at step 4620: 9.101338386535645
test at step 4620: 0.8040540814399719
test loss at step 4620: 3.128110885620117
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4630: 1.0
train loss at step 4630: 2.6518750019022264e-05
train at step 4640: 1.0
train loss at step 4640: 2.8597560230991803e-05
train at step 4650: 1.0
train loss at step 4650: 2.5683140847831964e-05
dev at step 4650: 0.5
dev loss at step 4650: 9.108270645141602
test at step 4650: 0.8040540814399719
test loss at step 4650: 3.1302237510681152
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4660: 1.0
train loss at step 4660: 2.863457120838575e-05
train at step 4670: 1.0
train loss at step 4670: 2.667835542524699e-05
train at step 4680: 1.0
train loss at step 4680: 2.7140320526086725e-05
dev at step 4680: 0.5
dev loss at step 4680: 9.120611190795898
test at step 4680: 0.8040540814399719
test loss at step 4680: 3.1343741416931152
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4690: 1.0
train loss at step 4690: 2.5429657398490235e-05
train at step 4700: 1.0
train loss at step 4700: 2.742203650996089e-05
train at step 4710: 1.0
train loss at step 4710: 2.4626808226457797e-05
dev at step 4710: 0.5
dev loss at step 4710: 9.127399444580078
test at step 4710: 0.8040540814399719
test loss at step 4710: 3.13643741607666
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4720: 1.0
train loss at step 4720: 2.746353311522398e-05
train at step 4730: 1.0
train loss at step 4730: 2.559222593845334e-05
train at step 4740: 1.0
train loss at step 4740: 2.6036310373456217e-05
dev at step 4740: 0.5
dev loss at step 4740: 9.139738082885742
test at step 4740: 0.8040540814399719
test loss at step 4740: 3.140591859817505
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4750: 1.0
train loss at step 4750: 2.4394195861532353e-05
train at step 4760: 1.0
train loss at step 4760: 2.6306845029466785e-05
train at step 4770: 1.0
train loss at step 4770: 2.3627080736332573e-05
dev at step 4770: 0.5
dev loss at step 4770: 9.14633560180664
test at step 4770: 0.8040540814399719
test loss at step 4770: 3.1425881385803223
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4780: 1.0
train loss at step 4780: 2.6355808586231433e-05
train at step 4790: 1.0
train loss at step 4790: 2.4560478777857497e-05
train at step 4800: 1.0
train loss at step 4800: 2.497774039511569e-05
dev at step 4800: 0.5
dev loss at step 4800: 9.158677101135254
test at step 4800: 0.8040540814399719
test loss at step 4800: 3.14674711227417
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4810: 1.0
train loss at step 4810: 2.3414597308146767e-05
train at step 4820: 1.0
train loss at step 4820: 2.5241559342248365e-05
train at step 4830: 1.0
train loss at step 4830: 2.2677264496451244e-05
dev at step 4830: 0.5
dev loss at step 4830: 9.165116310119629
test at step 4830: 0.8040540814399719
test loss at step 4830: 3.148688554763794
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4840: 1.0
train loss at step 4840: 2.5300972993136384e-05
train at step 4850: 1.0
train loss at step 4850: 2.35682036873186e-05
train at step 4860: 1.0
train loss at step 4860: 2.3971304472070187e-05
dev at step 4860: 0.5
dev loss at step 4860: 9.17751407623291
test at step 4860: 0.8040540814399719
test loss at step 4860: 3.152872085571289
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4870: 1.0
train loss at step 4870: 2.2471493139164522e-05
train at step 4880: 1.0
train loss at step 4880: 2.4236611352534965e-05
train at step 4890: 1.0
train loss at step 4890: 2.17617089219857e-05
dev at step 4890: 0.5
dev loss at step 4890: 9.183745384216309
test at step 4890: 0.8040540814399719
test loss at step 4890: 3.154738664627075
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4900: 1.0
train loss at step 4900: 2.4290822693728842e-05
train at step 4910: 1.0
train loss at step 4910: 2.2627325961366296e-05
train at step 4920: 1.0
train loss at step 4920: 2.3008822608971968e-05
dev at step 4920: 0.5
dev loss at step 4920: 9.196144104003906
test at step 4920: 0.8040540814399719
test loss at step 4920: 3.1589267253875732
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4930: 1.0
train loss at step 4930: 2.1576808649115264e-05
train at step 4940: 1.0
train loss at step 4940: 2.326592402823735e-05
train at step 4950: 1.0
train loss at step 4950: 2.088786641252227e-05
dev at step 4950: 0.5
dev loss at step 4950: 9.202245712280273
test at step 4950: 0.8040540814399719
test loss at step 4950: 3.1607484817504883
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4960: 1.0
train loss at step 4960: 2.3320892069023103e-05
train at step 4970: 1.0
train loss at step 4970: 2.172965105273761e-05
train at step 4980: 1.0
train loss at step 4980: 2.2092519429861568e-05
dev at step 4980: 0.5
dev loss at step 4980: 9.214693069458008
test at step 4980: 0.8040540814399719
test loss at step 4980: 3.164957046508789
tp: 117, tn: 2, fp: 29, fn: 0
accuracy: 0.8040540540540541, precision: 0.8013698630136986, recall: 1.0, F1: 0.8897338403041826
specificity: 0.06451612903225806, gmean: 0.254000254000381, mcc: 0.22737915798233302 

train at step 4990: 1.0
train loss at step 4990: 2.0721603505080566e-05
train at step 5000: 1.0
train loss at step 5000: 2.233918712590821e-05

