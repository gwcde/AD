train at step 1510: 0.6937500238418579
train loss at step 1510: 0.7233795523643494
train at step 1520: 0.8500000238418579
train loss at step 1520: 0.2963032126426697
train at step 1530: 0.981249988079071
train loss at step 1530: 0.07739027589559555
dev at step 1530: 0.5
New best on dev at step 1530: 0.5
dev loss at step 1530: 0.4935644268989563
test at step 1530: 0.2635135054588318
test loss at step 1530: 5.109437942504883
tp: 10, tn: 29, fp: 2, fn: 107
accuracy: 0.2635135135135135, precision: 0.8333333333333334, recall: 0.08547008547008547, F1: 0.15503875968992248
specificity: 0.9354838709677419, gmean: 0.28276471917037194, mcc: 0.031237749454422235 

train at step 1540: 1.0
train loss at step 1540: 0.013858409598469734
train at step 1550: 1.0
train loss at step 1550: 0.0034855646081268787
train at step 1560: 1.0
train loss at step 1560: 0.00168007449246943
dev at step 1560: 0.75
New best on dev at step 1560: 0.75
dev loss at step 1560: 0.3018936812877655
test at step 1560: 0.36486485600471497
test loss at step 1560: 4.404655456542969
tp: 25, tn: 29, fp: 2, fn: 92
accuracy: 0.36486486486486486, precision: 0.9259259259259259, recall: 0.21367521367521367, F1: 0.3472222222222222
specificity: 0.9354838709677419, gmean: 0.4470902772581263, mcc: 0.1571624969301972 

train at step 1570: 1.0
train loss at step 1570: 0.0010315767722204328
train at step 1580: 1.0
train loss at step 1580: 0.0007526460685767233
train at step 1590: 1.0
train loss at step 1590: 0.0006217655027285218
dev at step 1590: 0.75
dev loss at step 1590: 0.47190234065055847
test at step 1590: 0.36486485600471497
test loss at step 1590: 4.849236011505127
tp: 25, tn: 29, fp: 2, fn: 92
accuracy: 0.36486486486486486, precision: 0.9259259259259259, recall: 0.21367521367521367, F1: 0.3472222222222222
specificity: 0.9354838709677419, gmean: 0.4470902772581263, mcc: 0.1571624969301972 

train at step 1600: 1.0
train loss at step 1600: 0.0005353590240702033
train at step 1610: 1.0
train loss at step 1610: 0.0005080564296804368
train at step 1620: 1.0
train loss at step 1620: 0.00045224279165267944
dev at step 1620: 0.75
dev loss at step 1620: 0.5032972693443298
test at step 1620: 0.3581081032752991
test loss at step 1620: 4.90284538269043
tp: 25, tn: 28, fp: 3, fn: 92
accuracy: 0.3581081081081081, precision: 0.8928571428571429, recall: 0.21367521367521367, F1: 0.3448275862068965
specificity: 0.9032258064516129, gmean: 0.43931420098889995, mcc: 0.12145696932229409 

train at step 1630: 1.0
train loss at step 1630: 0.0004353427793830633
train at step 1640: 1.0
train loss at step 1640: 0.0003931713290512562
train at step 1650: 1.0
train loss at step 1650: 0.0003831103094853461
dev at step 1650: 0.75
dev loss at step 1650: 0.5214742422103882
test at step 1650: 0.36486485600471497
test loss at step 1650: 4.927089214324951
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1660: 1.0
train loss at step 1660: 0.0003499930026009679
train at step 1670: 1.0
train loss at step 1670: 0.0003438228159211576
train at step 1680: 1.0
train loss at step 1680: 0.00031412445241585374
dev at step 1680: 0.75
dev loss at step 1680: 0.5347721576690674
test at step 1680: 0.36486485600471497
test loss at step 1680: 4.941468715667725
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1690: 1.0
train loss at step 1690: 0.0003094912099186331
train at step 1700: 1.0
train loss at step 1700: 0.0002845214621629566
train at step 1710: 1.0
train loss at step 1710: 0.0002814926556311548
dev at step 1710: 0.75
dev loss at step 1710: 0.5488821268081665
test at step 1710: 0.36486485600471497
test loss at step 1710: 4.960843563079834
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1720: 1.0
train loss at step 1720: 0.0002610289375297725
train at step 1730: 1.0
train loss at step 1730: 0.00025957729667425156
train at step 1740: 1.0
train loss at step 1740: 0.000239649394643493
dev at step 1740: 0.75
dev loss at step 1740: 0.558944821357727
test at step 1740: 0.36486485600471497
test loss at step 1740: 4.970765113830566
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1750: 1.0
train loss at step 1750: 0.0002386011474300176
train at step 1760: 1.0
train loss at step 1760: 0.00022199082013685256
train at step 1770: 1.0
train loss at step 1770: 0.000221209556912072
dev at step 1770: 0.75
dev loss at step 1770: 0.5704408288002014
test at step 1770: 0.36486485600471497
test loss at step 1770: 4.986377716064453
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1780: 1.0
train loss at step 1780: 0.0002068807661999017
train at step 1790: 1.0
train loss at step 1790: 0.00020730243704747409
train at step 1800: 1.0
train loss at step 1800: 0.00019255437655374408
dev at step 1800: 0.75
dev loss at step 1800: 0.5789897441864014
test at step 1800: 0.36486485600471497
test loss at step 1800: 4.9949164390563965
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1810: 1.0
train loss at step 1810: 0.0001929674472194165
train at step 1820: 1.0
train loss at step 1820: 0.00018095441919285804
train at step 1830: 1.0
train loss at step 1830: 0.00018115711282007396
dev at step 1830: 0.75
dev loss at step 1830: 0.5890026688575745
test at step 1830: 0.36486485600471497
test loss at step 1830: 5.008710861206055
tp: 26, tn: 28, fp: 3, fn: 91
accuracy: 0.36486486486486486, precision: 0.896551724137931, recall: 0.2222222222222222, F1: 0.35616438356164376
specificity: 0.9032258064516129, gmean: 0.4480143366881647, mcc: 0.12860715742434142 

train at step 1840: 1.0
train loss at step 1840: 0.00017036586359608918
train at step 1850: 1.0
train loss at step 1850: 0.00017160072457045317
train at step 1860: 1.0
train loss at step 1860: 0.00016002339543774724
dev at step 1860: 0.75
dev loss at step 1860: 0.5964633822441101
test at step 1860: 0.37162160873413086
test loss at step 1860: 5.016140937805176
tp: 27, tn: 28, fp: 3, fn: 90
accuracy: 0.3716216216216216, precision: 0.9, recall: 0.23076923076923078, F1: 0.3673469387755102
specificity: 0.9032258064516129, gmean: 0.45654870995958013, mcc: 0.13563159233303201 

train at step 1870: 1.0
train loss at step 1870: 0.0001610693580005318
train at step 1880: 1.0
train loss at step 1880: 0.00015192742284853011
train at step 1890: 1.0
train loss at step 1890: 0.00015257456107065082
dev at step 1890: 0.75
dev loss at step 1890: 0.6053656339645386
test at step 1890: 0.37162160873413086
test loss at step 1890: 5.028471946716309
tp: 27, tn: 28, fp: 3, fn: 90
accuracy: 0.3716216216216216, precision: 0.9, recall: 0.23076923076923078, F1: 0.3673469387755102
specificity: 0.9032258064516129, gmean: 0.45654870995958013, mcc: 0.13563159233303201 

train at step 1900: 1.0
train loss at step 1900: 0.00014403446402866393
train at step 1910: 1.0
train loss at step 1910: 0.00014564504090230912
train at step 1920: 1.0
train loss at step 1920: 0.00013618897355627269
dev at step 1920: 0.75
dev loss at step 1920: 0.6120019555091858
test at step 1920: 0.37162160873413086
test loss at step 1920: 5.035000324249268
tp: 27, tn: 28, fp: 3, fn: 90
accuracy: 0.3716216216216216, precision: 0.9, recall: 0.23076923076923078, F1: 0.3673469387755102
specificity: 0.9032258064516129, gmean: 0.45654870995958013, mcc: 0.13563159233303201 

train at step 1930: 1.0
train loss at step 1930: 0.00013751568621955812
train at step 1940: 1.0
train loss at step 1940: 0.00013030199625063688
train at step 1950: 1.0
train loss at step 1950: 0.00013115456386003643
dev at step 1950: 0.75
dev loss at step 1950: 0.6200643181800842
test at step 1950: 0.37162160873413086
test loss at step 1950: 5.046205997467041
tp: 27, tn: 28, fp: 3, fn: 90
accuracy: 0.3716216216216216, precision: 0.9, recall: 0.23076923076923078, F1: 0.3673469387755102
specificity: 0.9032258064516129, gmean: 0.45654870995958013, mcc: 0.13563159233303201 

train at step 1960: 1.0
train loss at step 1960: 0.000124162805150263
train at step 1970: 1.0
train loss at step 1970: 0.0001259243581444025
train at step 1980: 1.0
train loss at step 1980: 0.00011798584455391392
dev at step 1980: 0.75
dev loss at step 1980: 0.6260592937469482
test at step 1980: 0.37162160873413086
test loss at step 1980: 5.052002429962158
tp: 27, tn: 28, fp: 3, fn: 90
accuracy: 0.3716216216216216, precision: 0.9, recall: 0.23076923076923078, F1: 0.3673469387755102
specificity: 0.9032258064516129, gmean: 0.45654870995958013, mcc: 0.13563159233303201 

train at step 1990: 1.0
train loss at step 1990: 0.00011941089906031266
train at step 2000: 1.0
train loss at step 2000: 0.00011356198228895664
train at step 2010: 1.0
train loss at step 2010: 0.00011450461897766218
dev at step 2010: 0.75
dev loss at step 2010: 0.6334627270698547
test at step 2010: 0.37837839126586914
test loss at step 2010: 5.062318325042725
tp: 28, tn: 28, fp: 3, fn: 89
accuracy: 0.3783783783783784, precision: 0.9032258064516129, recall: 0.23931623931623933, F1: 0.37837837837837845
specificity: 0.9032258064516129, gmean: 0.46492644929427007, mcc: 0.14254204576785223 

train at step 2020: 1.0
train loss at step 2020: 0.00010863153875106946
train at step 2030: 1.0
train loss at step 2030: 0.00011043691483791918
train at step 2040: 1.0
train loss at step 2040: 0.00010362137982156128
dev at step 2040: 0.75
dev loss at step 2040: 0.6389449238777161
test at step 2040: 0.37837839126586914
test loss at step 2040: 5.067516326904297
tp: 28, tn: 28, fp: 3, fn: 89
accuracy: 0.3783783783783784, precision: 0.9032258064516129, recall: 0.23931623931623933, F1: 0.37837837837837845
specificity: 0.9032258064516129, gmean: 0.46492644929427007, mcc: 0.14254204576785223 

train at step 2050: 1.0
train loss at step 2050: 0.00010506952821742743
train at step 2060: 1.0
train loss at step 2060: 0.00010023407230619341
train at step 2070: 1.0
train loss at step 2070: 0.00010119006037712097
dev at step 2070: 0.75
dev loss at step 2070: 0.6458218097686768
test at step 2070: 0.37837839126586914
test loss at step 2070: 5.07711935043335
tp: 28, tn: 28, fp: 3, fn: 89
accuracy: 0.3783783783783784, precision: 0.9032258064516129, recall: 0.23931623931623933, F1: 0.37837837837837845
specificity: 0.9032258064516129, gmean: 0.46492644929427007, mcc: 0.14254204576785223 

train at step 2080: 1.0
train loss at step 2080: 9.616088209440932e-05
train at step 2090: 1.0
train loss at step 2090: 9.796467929845676e-05
train at step 2100: 1.0
train loss at step 2100: 9.201600914821029e-05
dev at step 2100: 0.75
dev loss at step 2100: 0.6508991718292236
test at step 2100: 0.37837839126586914
test loss at step 2100: 5.0818586349487305
tp: 28, tn: 28, fp: 3, fn: 89
accuracy: 0.3783783783783784, precision: 0.9032258064516129, recall: 0.23931623931623933, F1: 0.37837837837837845
specificity: 0.9032258064516129, gmean: 0.46492644929427007, mcc: 0.14254204576785223 

train at step 2110: 1.0
train loss at step 2110: 9.343586134491488e-05
train at step 2120: 1.0
train loss at step 2120: 8.937041275203228e-05
train at step 2130: 1.0
train loss at step 2130: 9.031444642459974e-05
dev at step 2130: 0.75
dev loss at step 2130: 0.6573346257209778
test at step 2130: 0.37837839126586914
test loss at step 2130: 5.090847969055176
tp: 28, tn: 28, fp: 3, fn: 89
accuracy: 0.3783783783783784, precision: 0.9032258064516129, recall: 0.23931623931623933, F1: 0.37837837837837845
specificity: 0.9032258064516129, gmean: 0.46492644929427007, mcc: 0.14254204576785223 

train at step 2140: 1.0
train loss at step 2140: 8.593776874477044e-05
train at step 2150: 1.0
train loss at step 2150: 8.769459236646071e-05
train at step 2160: 1.0
train loss at step 2160: 8.243332558777183e-05
dev at step 2160: 0.75
dev loss at step 2160: 0.6620551347732544
test at step 2160: 0.38513514399528503
test loss at step 2160: 5.095137119293213
tp: 29, tn: 28, fp: 3, fn: 88
accuracy: 0.38513513513513514, precision: 0.90625, recall: 0.24786324786324787, F1: 0.38926174496644295
specificity: 0.9032258064516129, gmean: 0.4731558748879676, mcc: 0.14934916434033063 

train at step 2170: 1.0
train loss at step 2170: 8.380998042412102e-05
train at step 2180: 1.0
train loss at step 2180: 8.035149949137121e-05
train at step 2190: 1.0
train loss at step 2190: 8.126347529469058e-05
dev at step 2190: 0.75
dev loss at step 2190: 0.668135404586792
test at step 2190: 0.38513514399528503
test loss at step 2190: 5.103652477264404
tp: 29, tn: 28, fp: 3, fn: 88
accuracy: 0.38513513513513514, precision: 0.90625, recall: 0.24786324786324787, F1: 0.38926174496644295
specificity: 0.9032258064516129, gmean: 0.4731558748879676, mcc: 0.14934916434033063 

train at step 2200: 1.0
train loss at step 2200: 7.741418812656775e-05
train at step 2210: 1.0
train loss at step 2210: 7.911510328995064e-05
train at step 2220: 1.0
train loss at step 2220: 7.441018533427268e-05
dev at step 2220: 0.75
dev loss at step 2220: 0.6725738048553467
test at step 2220: 0.38513514399528503
test loss at step 2220: 5.107616901397705
tp: 29, tn: 28, fp: 3, fn: 88
accuracy: 0.38513513513513514, precision: 0.90625, recall: 0.24786324786324787, F1: 0.38926174496644295
specificity: 0.9032258064516129, gmean: 0.4731558748879676, mcc: 0.14934916434033063 

train at step 2230: 1.0
train loss at step 2230: 7.572354661533609e-05
train at step 2240: 1.0
train loss at step 2240: 7.274914241861552e-05
train at step 2250: 1.0
train loss at step 2250: 7.362387259490788e-05
dev at step 2250: 0.75
dev loss at step 2250: 0.6783243417739868
test at step 2250: 0.38513514399528503
test loss at step 2250: 5.115643501281738
tp: 29, tn: 28, fp: 3, fn: 88
accuracy: 0.38513513513513514, precision: 0.90625, recall: 0.24786324786324787, F1: 0.38926174496644295
specificity: 0.9032258064516129, gmean: 0.4731558748879676, mcc: 0.14934916434033063 

train at step 2260: 1.0
train loss at step 2260: 7.019842450972646e-05
train at step 2270: 1.0
train loss at step 2270: 7.183376146713272e-05
train at step 2280: 1.0
train loss at step 2280: 6.759287498425692e-05
dev at step 2280: 0.75
dev loss at step 2280: 0.6825377941131592
test at step 2280: 0.3918918967247009
test loss at step 2280: 5.1193718910217285
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2290: 1.0
train loss at step 2290: 6.884962203912437e-05
train at step 2300: 1.0
train loss at step 2300: 6.626251706620678e-05
train at step 2310: 1.0
train loss at step 2310: 6.708806176902726e-05
dev at step 2310: 0.75
dev loss at step 2310: 0.6880279779434204
test at step 2310: 0.3918918967247009
test loss at step 2310: 5.127048492431641
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2320: 1.0
train loss at step 2320: 6.402018334483728e-05
train at step 2330: 1.0
train loss at step 2330: 6.558324093930423e-05
train at step 2340: 1.0
train loss at step 2340: 6.174082955112681e-05
dev at step 2340: 0.75
dev loss at step 2340: 0.6920272707939148
test at step 2340: 0.3918918967247009
test loss at step 2340: 5.1305108070373535
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2350: 1.0
train loss at step 2350: 6.292235775617883e-05
train at step 2360: 1.0
train loss at step 2360: 6.0662969190161675e-05
train at step 2370: 1.0
train loss at step 2370: 6.144603685243055e-05
dev at step 2370: 0.75
dev loss at step 2370: 0.697278618812561
test at step 2370: 0.3918918967247009
test loss at step 2370: 5.137840270996094
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2380: 1.0
train loss at step 2380: 5.8665707911131904e-05
train at step 2390: 1.0
train loss at step 2390: 6.016468978486955e-05
train at step 2400: 1.0
train loss at step 2400: 5.664852142217569e-05
dev at step 2400: 0.75
dev loss at step 2400: 0.7011035680770874
test at step 2400: 0.3918918967247009
test loss at step 2400: 5.14110803604126
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2410: 1.0
train loss at step 2410: 5.777195838163607e-05
train at step 2420: 1.0
train loss at step 2420: 5.5785181757528335e-05
train at step 2430: 1.0
train loss at step 2430: 5.652652544085868e-05
dev at step 2430: 0.75
dev loss at step 2430: 0.7061293721199036
test at step 2430: 0.3918918967247009
test loss at step 2430: 5.148087978363037
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

train at step 2440: 1.0
train loss at step 2440: 5.399797737482004e-05
train at step 2450: 1.0
train loss at step 2450: 5.5432890803785995e-05
train at step 2460: 1.0
train loss at step 2460: 5.220498496782966e-05
dev at step 2460: 0.75
dev loss at step 2460: 0.709814727306366
test at step 2460: 0.3918918967247009
test loss at step 2460: 5.151218891143799
tp: 30, tn: 28, fp: 3, fn: 87
accuracy: 0.3918918918918919, precision: 0.9090909090909091, recall: 0.2564102564102564, F1: 0.3999999999999999
specificity: 0.9032258064516129, gmean: 0.48124459542795767, mcc: 0.15606262078599573 

