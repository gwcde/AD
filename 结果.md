### MLP

> batch_size = 4 , length = 160000, learning_rate = 1e-5, Adam

```python
classifier(
  (mlp): Sequential(
    (0): Linear(in_features=160000, out_features=1024, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
```

> train_acc = 0.72  val_acc = 0.641  0.663(best)  

![image-20230103194253107](images/image-20230103194253107.png)



### LSTM

> batch_size = 4, length = 160000, learning_rate = 1e-5

```python
LSTM(
  (lstm): LSTM(160000, 256, num_layers=2, batch_first=True)
  (linear): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=256, out_features=1, bias=True)
  )
)
```

> train_acc = 0.712   val_acc = 0.651 0.674(best)

![image-20230103194921874](images/image-20230103194921874.png)

### CNN

> batch_size = 4, length = 160000, learning_rate = 1e-5 

```python
CNN(
  (cnn1): Conv1d(1, 32, kernel_size=(3,), stride=(1,))
  (cnn2): Conv1d(32, 64, kernel_size=(3,), stride=(1,))
  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (relu1): ReLU()
  (cnn3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))
  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (relu2): ReLU()
  (cnn4): Conv1d(128, 256, kernel_size=(3,), stride=(1,))
  (cnn5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))
  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (relu3): ReLU()
  (linear): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=639488, out_features=512, bias=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
)
```

> train_acc = 0.640  val_acc = 0.684  0.696(best)  12G

 ![image-20230103224541330](images/image-20230103224541330.png)